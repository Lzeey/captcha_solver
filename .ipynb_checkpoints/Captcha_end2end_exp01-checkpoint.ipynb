{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captcha solver\n",
    "## End-to-End variant\n",
    "\n",
    "For this experiment, we will build the captcha solver in an end-to-end manner. The number of characters range from 3 to 7 (typical of many captcha solvers).\n",
    "\n",
    "For captchas shorter than 7, we zero-pad the array.\n",
    "\n",
    "e.g. `a09` $\\rightarrow [11, 1, 10, 0, 0, 0, 0]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data_npy'\n",
    "MODEL_NAME = 'char_end2end_exp01.h5'\n",
    "batch_size = 32\n",
    "\n",
    "width = 150\n",
    "height = 60 #Uniform squashing of images\n",
    "\n",
    "MAX_CAPTCHA_LEN = 7\n",
    "\n",
    "char_set = ('_0123456789'\n",
    "            'abcdefghijklmnopqrstuvwxyz'\n",
    "            'ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "char_map = {char:idx for idx, char in enumerate(char_set)}\n",
    "num_classes = len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225120, 60, 150, 3) (225120, 7)\n",
      "(22313, 60, 150, 3) (22313, 7)\n"
     ]
    }
   ],
   "source": [
    "#Load training data\n",
    "train_X = np.load(os.path.join(DATA_DIR, 'train_X.npy')).astype(np.float32)/255\n",
    "train_Y = np.load(os.path.join(DATA_DIR, 'train_y.npy'))\n",
    "\n",
    "val_X = np.load(os.path.join(DATA_DIR, 'val_X.npy')).astype(np.float32)/255\n",
    "val_Y = np.load(os.path.join(DATA_DIR, 'val_y.npy'))\n",
    "\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(val_X.shape, val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to reverse encoding\n",
    "def array_to_string(y):\n",
    "    s = ''.join(char_set[i] for i in y).rstrip('_')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_X = train_X.astype(np.float32) / 255\n",
    "# val_X = val_X.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sxHCME\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACoCAYAAADw6BWzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDyEvacE0Ff7IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef06eecc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected = np.random.randint(0, len(train_X))\n",
    "print(array_to_string(train_Y[selected]))\n",
    "plt.imshow(train_X[selected])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                               shear_range=0.05,\n",
    "                               channel_shift_range=0.2,\n",
    "                               width_shift_range=0.05,\n",
    "                               height_shift_range=0.05,\n",
    "                               fill_mode='reflect'\n",
    "                              )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = train_datagen.flow(train_X, train_Y, batch_size=batch_size, shuffle=True)\n",
    "# val_generator = val_datagen.flow(val_X, val_Y, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mixed_block(x, num_filt, block_num):\n",
    "    branch1x1 = Conv2D(num_filt, (1,1), activation='relu', padding='same', name='block%d_1x1_c1'%block_num)(x)\n",
    "    branch1x1 = BatchNormalization(name='block%d_1x1_bn1'%block_num)(branch1x1)\n",
    "    \n",
    "    branch3x3 = Conv2D(int(num_filt*0.75), (1,1), activation='relu', padding='same', name='block%d_3x3_c1'%block_num)(x)\n",
    "    branch3x3 = BatchNormalization( name='block%d_3x3_bn1'%block_num)(branch3x3)\n",
    "    branch3x3 = Conv2D(num_filt, (3,3), activation='relu', padding='same', name='block%d_3x3_c2'%block_num)(branch3x3)\n",
    "    branch3x3 = BatchNormalization( name='block%d_3x3_bn2'%block_num)(branch3x3)\n",
    "    \n",
    "    branch5x5 = Conv2D(int(num_filt*0.75), (1,1), activation='relu', padding='same', name='block%d_5x5_c1'%block_num)(x)\n",
    "    branch5x5 = BatchNormalization(name='block%d_5x5_bn1'%block_num)(branch5x5)\n",
    "    branch5x5 = Conv2D(num_filt, (3,3), activation='relu', padding='same', name='block%d_5x5_c2'%block_num)(branch5x5)\n",
    "    branch5x5 = Conv2D(num_filt, (3,3), activation='relu', padding='same', name='block%d_5x5_c3'%block_num)(branch5x5)\n",
    "    branch5x5 = BatchNormalization(name='block%d_5x5_bn2'%block_num)(branch5x5)    \n",
    "    \n",
    "    #branch5x5 = Conv2D(num_filt, (5,5), activation='relu', padding='same', name='block%d_5x5_c2'%block_num)(branch5x5)\n",
    "    #branch5x5 = BatchNormalization(name='block%d_5x5_bn2'%block_num)(branch5x5)\n",
    "    \n",
    "    branch_pool = AveragePooling2D((3,3), strides=(1,1), padding='same', name='block%d_pool_pool1'%block_num)(x)\n",
    "    branch_pool = Conv2D(int(num_filt//2), (1,1), activation='relu', name='block%d_pool_c1'%block_num)(branch_pool)\n",
    "    \n",
    "    out = Concatenate(name='mixed_%d'%block_num, axis=3)([branch1x1, branch3x3, branch5x5, branch_pool])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 60, 150, 3)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1_c1 (Conv2D)                (None, 58, 148, 32)   896         input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1_bn1 (BatchNormalization)   (None, 58, 148, 32)   128         conv1_c1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1_c2 (Conv2D)                (None, 58, 148, 64)   18496       conv1_bn1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1_bn2 (BatchNormalization)   (None, 58, 148, 64)   256         conv1_c2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1_pool1 (MaxPooling2D)       (None, 28, 73, 64)    0           conv1_bn2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2_c1 (Conv2D)                (None, 26, 71, 128)   73856       conv1_pool1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2_bn1 (BatchNormalization)   (None, 26, 71, 128)   512         conv2_c1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2_c2 (Conv2D)                (None, 24, 69, 192)   221376      conv2_bn1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2_bn2 (BatchNormalization)   (None, 24, 69, 192)   768         conv2_c2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2_pool1 (MaxPooling2D)       (None, 11, 34, 192)   0           conv2_bn2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 11, 34, 192)   0           conv2_pool1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_c1 (Conv2D)           (None, 11, 34, 48)    9264        dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_c1 (Conv2D)           (None, 11, 34, 48)    9264        dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_bn1 (BatchNormalizati (None, 11, 34, 48)    192         block0_5x5_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_bn1 (BatchNormalizati (None, 11, 34, 48)    192         block0_3x3_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_c2 (Conv2D)           (None, 11, 34, 64)    27712       block0_5x5_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block0_1x1_c1 (Conv2D)           (None, 11, 34, 64)    12352       dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_c2 (Conv2D)           (None, 11, 34, 64)    27712       block0_3x3_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_c3 (Conv2D)           (None, 11, 34, 64)    36928       block0_5x5_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_pool_pool1 (AveragePoolin (None, 11, 34, 192)   0           dropout_34[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block0_1x1_bn1 (BatchNormalizati (None, 11, 34, 64)    256         block0_1x1_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_bn2 (BatchNormalizati (None, 11, 34, 64)    256         block0_3x3_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_bn2 (BatchNormalizati (None, 11, 34, 64)    256         block0_5x5_c3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_pool_c1 (Conv2D)          (None, 11, 34, 32)    6176        block0_pool_pool1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed_0 (Concatenate)            (None, 11, 34, 224)   0           block0_1x1_bn1[0][0]             \n",
      "                                                                   block0_3x3_bn2[0][0]             \n",
      "                                                                   block0_5x5_bn2[0][0]             \n",
      "                                                                   block0_pool_c1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_c1 (Conv2D)           (None, 11, 34, 72)    16200       mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_c1 (Conv2D)           (None, 11, 34, 72)    16200       mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_bn1 (BatchNormalizati (None, 11, 34, 72)    288         block1_5x5_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_bn1 (BatchNormalizati (None, 11, 34, 72)    288         block1_3x3_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_c2 (Conv2D)           (None, 11, 34, 96)    62304       block1_5x5_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block1_1x1_c1 (Conv2D)           (None, 11, 34, 96)    21600       mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_c2 (Conv2D)           (None, 11, 34, 96)    62304       block1_3x3_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_c3 (Conv2D)           (None, 11, 34, 96)    83040       block1_5x5_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool_pool1 (AveragePoolin (None, 11, 34, 224)   0           mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_1x1_bn1 (BatchNormalizati (None, 11, 34, 96)    384         block1_1x1_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_bn2 (BatchNormalizati (None, 11, 34, 96)    384         block1_3x3_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_bn2 (BatchNormalizati (None, 11, 34, 96)    384         block1_5x5_c3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool_c1 (Conv2D)          (None, 11, 34, 48)    10800       block1_pool_pool1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed_1 (Concatenate)            (None, 11, 34, 336)   0           block1_1x1_bn1[0][0]             \n",
      "                                                                   block1_3x3_bn2[0][0]             \n",
      "                                                                   block1_5x5_bn2[0][0]             \n",
      "                                                                   block1_pool_c1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_pool1 (MaxPooling2D)       (None, 5, 16, 336)    0           mixed_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)             (None, 5, 16, 336)    0           conv3_pool1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_c1 (Conv2D)           (None, 5, 16, 93)     31341       dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_c1 (Conv2D)           (None, 5, 16, 93)     31341       dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_bn1 (BatchNormalizati (None, 5, 16, 93)     372         block2_5x5_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_bn1 (BatchNormalizati (None, 5, 16, 93)     372         block2_3x3_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_c2 (Conv2D)           (None, 5, 16, 124)    103912      block2_5x5_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block2_1x1_c1 (Conv2D)           (None, 5, 16, 124)    41788       dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_c2 (Conv2D)           (None, 5, 16, 124)    103912      block2_3x3_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_c3 (Conv2D)           (None, 5, 16, 124)    138508      block2_5x5_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool_pool1 (AveragePoolin (None, 5, 16, 336)    0           dropout_35[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "block2_1x1_bn1 (BatchNormalizati (None, 5, 16, 124)    496         block2_1x1_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_bn2 (BatchNormalizati (None, 5, 16, 124)    496         block2_3x3_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_bn2 (BatchNormalizati (None, 5, 16, 124)    496         block2_5x5_c3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool_c1 (Conv2D)          (None, 5, 16, 62)     20894       block2_pool_pool1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed_2 (Concatenate)            (None, 5, 16, 434)    0           block2_1x1_bn1[0][0]             \n",
      "                                                                   block2_3x3_bn2[0][0]             \n",
      "                                                                   block2_5x5_bn2[0][0]             \n",
      "                                                                   block2_pool_c1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)             (None, 5, 16, 434)    0           mixed_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glob (None, 434)           0           dropout_36[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 128)           55680       global_average_pooling2d_9[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 128)           512         dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 128)           0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "output0 (Dense)                  (None, 63)            8127        dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output1 (Dense)                  (None, 63)            8127        dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output2 (Dense)                  (None, 63)            8127        dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output3 (Dense)                  (None, 63)            8127        dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output4 (Dense)                  (None, 63)            8127        dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output5 (Dense)                  (None, 63)            8127        dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output6 (Dense)                  (None, 63)            8127        dropout_37[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,308,033\n",
      "Trainable params: 1,304,389\n",
      "Non-trainable params: 3,644\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(height, width, 3))\n",
    "x = Conv2D(32, (3,3), activation='relu', name='conv1_c1')(inputs)\n",
    "x = BatchNormalization(name='conv1_bn1')(x)\n",
    "x = Conv2D(64, (3,3), activation='relu', padding='same', name='conv1_c2')(x)\n",
    "x = BatchNormalization(name='conv1_bn2')(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv1_pool1')(x)\n",
    "\n",
    "x = Conv2D(128, (3,3), activation='relu', name='conv2_c1')(x)\n",
    "x = BatchNormalization(name='conv2_bn1')(x)\n",
    "x = Conv2D(192, (3,3), activation='relu', name='conv2_c2')(x)\n",
    "x = BatchNormalization(name='conv2_bn2')(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv2_pool1')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "#x = Conv2D(256, (3,3), activation='relu', name='conv3_c1')(x)\n",
    "x = mixed_block(x, 64, 0)\n",
    "#x = BatchNormalization(name='conv3_bn1')(x)\n",
    "x = mixed_block(x, 96, 1)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv3_pool1')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = mixed_block(x, 124, 2)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "loss_list = []\n",
    "output_names = ['output' + str(i) for i in range(MAX_CAPTCHA_LEN)]\n",
    "for output in output_names:\n",
    "    dense_output = Dense(num_classes, activation='softmax', name=output)(x)\n",
    "    loss_list.append(dense_output)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=loss_list)\n",
    "\n",
    "opt = keras.optimizers.adam(decay=1e-6)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=\"sparse_categorical_crossentropy\",)\n",
    "#               loss_weights={\n",
    "#                  'output0': 0.025,\n",
    "#                  'output1': 0.025,\n",
    "#                  'output2': 0.2,\n",
    "#                  'output3': 0.5,\n",
    "#                  'output4': 0.2,\n",
    "#                  'output5': 0.025,\n",
    "#                  'output6': 0.025\n",
    "#               }),\n",
    "              #metric={output:['accuracy'] for output in output_names})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGenerator(X, Y, datagen, batch_size=32, shuffle=True):\n",
    "    batches = datagen.flow(X, Y, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    while True:\n",
    "        x, y = batches.next()\n",
    "        yield x, {name:y[:,idx] for idx, name in enumerate(output_names)}\n",
    "        \n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct = y_true == y_pred\n",
    "    correct = np.min(correct, axis=1)\n",
    "    return np.sum(correct) / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 1/1\n",
      "225120/225120 [==============================] - 1478s - loss: 19.9966 - output0_loss: 3.2872 - output1_loss: 3.7538 - output2_loss: 3.7897 - output3_loss: 3.4277 - output4_loss: 2.6881 - output5_loss: 1.9227 - output6_loss: 1.1274  \n",
      "Validation Acc: 0.0095\n",
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "225120/225120 [==============================] - 1515s - loss: 13.9474 - output0_loss: 1.4188 - output1_loss: 2.2744 - output2_loss: 2.9358 - output3_loss: 2.6689 - output4_loss: 2.1578 - output5_loss: 1.5852 - output6_loss: 0.9066  \n",
      "Validation Acc: 0.0632\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "225120/225120 [==============================] - 1485s - loss: 12.1816 - output0_loss: 1.1654 - output1_loss: 1.6737 - output2_loss: 2.6342 - output3_loss: 2.4352 - output4_loss: 2.0083 - output5_loss: 1.4375 - output6_loss: 0.8274  \n",
      "Validation Acc: 0.0469\n",
      "Epoch: 3\n",
      "Epoch 1/1\n",
      "225120/225120 [==============================] - 1500s - loss: 11.3438 - output0_loss: 1.0616 - output1_loss: 1.4617 - output2_loss: 2.3858 - output3_loss: 2.3494 - output4_loss: 1.9287 - output5_loss: 1.3726 - output6_loss: 0.7839  \n",
      "Validation Acc: 0.1319\n",
      "Epoch: 4\n",
      "Epoch 1/1\n",
      "225120/225120 [==============================] - 1485s - loss: 10.7300 - output0_loss: 1.0101 - output1_loss: 1.3633 - output2_loss: 2.0624 - output3_loss: 2.3014 - output4_loss: 1.8734 - output5_loss: 1.3470 - output6_loss: 0.7723  \n",
      "Validation Acc: 0.0872\n",
      "Epoch: 5\n",
      "Epoch 1/1\n",
      " 77600/225120 [=========>....................] - ETA: 963s - loss: 10.4082 - output0_loss: 0.9825 - output1_loss: 1.2935 - output2_loss: 1.9095 - output3_loss: 2.2696 - output4_loss: 1.8449 - output5_loss: 1.3466 - output6_loss: 0.7615"
     ]
    }
   ],
   "source": [
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n",
    "#               patience=3, min_lr=0.00001)\n",
    "# model_chkpt = ModelCheckpoint(filepath=MODEL_NAME, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# hist = model.fit_generator(createGenerator(train_X, train_Y, train_datagen, batch_size=32),\n",
    "#                     steps_per_epoch=len(train_X)//batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=createGenerator(val_X, val_Y, val_datagen, batch_size=32),\n",
    "#                    validation_steps=len(val_X)//batch_size,\n",
    "#                     callbacks=[reduce_lr, model_chkpt]) # , model_chkpt Weird serialization error\n",
    "\n",
    "# hist = model.fit(train_X, {name:train_Y[:,idx] for idx, name in enumerate(output_names)}, batch_size=batch_size,\n",
    "#                 shuffle=True,\n",
    "#                 epochs=epochs,\n",
    "#                 validation_data=(val_X, {name:val_Y[:,idx] for idx, name in enumerate(output_names)}),\n",
    "#                 callbacks=[reduce_lr, model_chkpt])\n",
    "\n",
    "#Perform manual iteration\n",
    "hist_acc = []\n",
    "prev_acc = 0.0\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: %d\"%epoch)\n",
    "    model.fit(train_X, {name:train_Y[:,idx] for idx, name in enumerate(output_names)}, batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    epochs=1)\n",
    "    #Evaluate validation here\n",
    "    preds = model.predict(val_X)\n",
    "    preds = np.concatenate([np.argmax(preds[idx], axis=1).reshape(-1, 1) for idx in range(len(preds))], axis=1)\n",
    "    epoch_val_acc = custom_accuracy(val_Y, preds)\n",
    "    print(\"Validation Acc: %.4f\"%epoch_val_acc)\n",
    "    hist_acc.append(epoch_val_acc)\n",
    "    #Check for improvement\n",
    "    if len(hist_acc) == 1 or hist_acc[-1] > hist_acc[-2]:\n",
    "        # Save model\n",
    "        print(\"Saving improved model %s\"%MODEL_NAME)\n",
    "        model.save(MODEL_NAME)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
