{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captcha solver\n",
    "## Stage 2 Variant\n",
    "\n",
    "For this experiment, we will build stage 2 of the captcha solver. This stage takes in an image that has been classified previously by the stage 1 classifier (telling the stage 2 that there are n characters). Assuming that the stage 1 classifier is mostly correct (0.98 acc), we will build a specialised classifier for each $n$ captcha length.\n",
    "\n",
    "i.e. If we wish to classify captchas of length 3 to 7, will need to build 5 separate classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data_npy'\n",
    "DATA_RAW_DIR = 'data'\n",
    "MODEL_NAME = 'char_stage2_exp01.h5'\n",
    "batch_size = 32\n",
    "\n",
    "width = 150\n",
    "height = 60 #Uniform squashing of images\n",
    "\n",
    "# This parameter determines the captcha len to use\n",
    "CAPTCHA_LEN = 7\n",
    "MODEL_NAME = str(CAPTCHA_LEN) + MODEL_NAME\n",
    "\n",
    "char_set = ('_0123456789'\n",
    "            'abcdefghijklmnopqrstuvwxyz'\n",
    "            'ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "char_map = {char:idx for idx, char in enumerate(char_set)}\n",
    "num_classes = len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load training data\n",
    "file_names = [os.path.join(DATA_DIR, str(CAPTCHA_LEN) + f) for f in ['train_X.npy', 'train_y.npy', 'val_X.npy', 'val_y.npy']]\n",
    "#Check if cache already exists\n",
    "if not all(os.path.exists(f) for f in file_names):\n",
    "    print(\"No previous cache exists for %d chars. Building...\"%CAPTCHA_LEN)\n",
    "    from utils_dump_to_npy import main as convert_path_to_npy\n",
    "    convert_path_to_npy(IMAGE_PATH=os.path.join('data', str(CAPTCHA_LEN)),\n",
    "                       OUTPUT_PATH=DATA_DIR,\n",
    "                       OUTPUT_NAME=str(CAPTCHA_LEN)+'train')\n",
    "    convert_path_to_npy(IMAGE_PATH=os.path.join('data_val', str(CAPTCHA_LEN)),\n",
    "                       OUTPUT_PATH=DATA_DIR,\n",
    "                       OUTPUT_NAME=str(CAPTCHA_LEN)+'val') \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230101, 60, 150, 3) (230101, 7)\n",
      "(29901, 60, 150, 3) (29901, 7)\n"
     ]
    }
   ],
   "source": [
    "train_X = np.load(os.path.join(DATA_DIR, str(CAPTCHA_LEN) + 'train_X.npy'))\n",
    "train_Y = np.load(os.path.join(DATA_DIR, str(CAPTCHA_LEN) + 'train_y.npy'))\n",
    "\n",
    "val_X = np.load(os.path.join(DATA_DIR, str(CAPTCHA_LEN) + 'val_X.npy'))\n",
    "val_Y = np.load(os.path.join(DATA_DIR, str(CAPTCHA_LEN) + 'val_y.npy'))\n",
    "\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(val_X.shape, val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper function to reverse encoding\n",
    "def array_to_string(y):\n",
    "    s = ''.join(char_set[i] for i in y).rstrip('_')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_X = train_X.astype(np.float32) / 255\n",
    "# val_X = val_X.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UbhDuA6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACmCAYAAAARWd7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvUuIZOuW3/ff8cqM9zMfVafu7YvafT0wmHYPNNGgj2m7\nEbJRDwxCtjF+gGYGgYzRA9G+V2CQNbFs44GxZSMLjGULjD2wjazBkXGjhpawQCBdd19d7jlVp/IZ\n73dkRGwP6vy+XPHVjsgdkRFZWZdckFRVVsR+fI/1rfVf/7VWEIahXuRFXuRFXuTzkMSnfoAXeZEX\neZEXiS8vSvtFXuRFXuQzkhel/SIv8iIv8hnJi9J+kRd5kRf5jORFab/Ii7zIi3xG8qK0X+RFXuRF\nPiN5lNIOguCPBkHwkyAIfj8Igj+7r4d6kRd5kRd5kWgJduVpB0GQkPT7kn5D0ntJvyfpT4Zh+JP9\nPd6LvMiLvMiLWHmMpf2HJf1BGIZfh2F4J+l/lPRb+3msF3mRF3mRF4mSxyjtLyS9Nf9+993vXuRF\nXuRFXuRAkjr0DYIgeMmTf5EXeZEX2UHCMAz83z1GaX8r6fvm32+++91H8uu//uv68ssvJUlffvml\n+/u2slgsdHd3p/l87v7MZrPKZrNKJpOSpOVyqeVyqfl8rul0qslkolwup1wu5z4Djn93d6d2u61W\nq6Wf/vSn+ulPf6put6vhcKjf/d3f1W/91m/p5OREb9680atXr5ROp5XJZFQoFFQsFpXJZNY+62w2\n093dncbjsYbDocbjsWazmabTqfsJgmDlJ51Ou/c5Pj7W8fGxcrmc8vm8e/Z18qMf/Ug/+tGPHhzD\n8Xis0Wik5XKpRCKhMAw1Go00mUxUKpVULpeVSqWUTCaVSDzsiNmxHA6Hmk6nyufzKhQKCoKP1ttH\nz/zbv/3bWi6Xury81Ndff63ZbKZGo6F6va5isahisfjgMxxChsOhBoOBUqmUCoWCjo6O3DPHGefn\nInGfd7lcarFYaDKZ6Ntvv9W7d+/UaDR0enqqYrGo4+NjpdPpgzxjGIbqdDrqdDpqtVr6q3/1r+pP\n/ak/pS+++EInJyc6Ojpy4x8lg8FA33zzjS4vL5XP55XL5VSr1dRoNDZ+b59ix3k6narf72s8Hrv/\nZy1v2sdfffWVvvrqK/fvH//4x5Gfe4zS/j1J/0wQBL8k6ULSn5T0r0d98Msvv9zLQg/DUHd3d5pM\nJk4hh2GodDq9ovySyaRSqZSOj49VLpc/ug7KJJVKqVwu6/j4WL1eT61WS/P53F13PB6r2+0qlUrp\n7u7OKVBJyuVyG581k8kok8kon8+r0Wi4Q2Q0Gun29lbNZtO9Bwo+kUg4RV0oFJTP57VcLpVOp92G\nse/pj00c4VDYpzAvg8FAg8FAyWRS+Xz+QaWNBEGgo6MjlUolTadTJZNJzedzLZfLyPeKe91txd5r\nMpmo3W4rk8m48T/Ufbd5LmTfz2L3ztHRkVvnw+FQyWRS6XRaqVTqIPfGcLi9vdXl5aU6nY7evXvn\n9gHPtE7m87n6/b5ub281n88VBIHm83nsPRH1PPbvYRiu3XfrnmcwGKjX67lrJZNJFQqFjd/zDdq9\nK+0wDBdBEPz7kv62PmDjfy0Mw3+y6/XiiLWgR6ORRqORsw6w7jZZv74EQaBUKqUwDFUoFFSr1TQe\nj91gTyYTN0l3d3c6Pz9XqVRSMpnceuEmEgml02nlcjnV63Vls1mnrKfTqcbjsebzubNuh8Ohut2u\nut2ubm5udHx8rEwm45T68fGxW0RxLOJDShiGms/n6vV6arfb7h3jCOOYzWZ1cnKi+XzuDrxMJuM2\nDRvnqd51NBrp5uZGyWRSi8VCs9nMKbJPIWEYarlcHnQMEomEksmkMpmMcrmclsulO4RzudxBrVZr\nnYZh6AyvdDr94PtmMhnV63WFYahiseg84Ye8003CeI9GIw2HQx0dHcXWL4lEQkdHR24MecZ9HXaP\nwrTDMPw/Jf2zD31uVzgk4n4rSptJTqVSqtVqbqNvIyjgQqGger2uXq+ndDqtN2/eaDKZ6O7uTrPZ\nTOPxWKVSSalUSqlUausJAP7AA6jValosFprP5xqPxxoMBg5CwcK/vb1174SVX6lU1Gg03HMnEgml\nUqm9jfG2YuGRfr+vVqulRqMR67s8cxAEyuVyymazTjnze+ke8kokErGtncfKcDjUzc2NgiBYsZY+\n1TgDX2w7Bts8r7W0c7mcBoOB+v2+UqmUqtXqytzsU8IwdEp7Mpnohz/8oTNyUqnUg0o7nU6rXq+7\nNQRcimewizDe/X5fzWbTKex1+sWOcyKRUCaTWfEU9wktHTwQKe1PaXOCgfEeHR25RZzL5baeJKsc\nCoWCTk5O1Ov1dHNzo1/5lV/RdDqVJAezlMtlh+9ta+34ioj3scr3+PjYHUpAK/wfi6jb7Wo+nzvY\nJplMKpvN6ld/9VfV6/XcxstkMo9atNsKm+zo6Ci2hWPXRRTcw6EGFMbcP4W1XSwW9fr1a0lSuVxW\nPp9XOp1+UqXNnDPf3W5XuVxOpVLJKaaHxjru89r1yfpZLBYaDodKp9Maj8fKZrPOaNm3YHwcHx/r\n137t11QsFpXNZh0sZeNYwDX+3uH3+4Cy7HXZ85vG2o5zMpl0n0dpPxtL+6mFwUin08rn81osFpI+\nbHCwx10kCALl83mlUil1u12Vy2UNh0N3/WKxqNPTU1WrVYeBP8b1svflIEqn086iXCwWqlQqmkwm\nK8q62Wyq3++r1+s5JZlOp1Uul1UqldxC5jB7CqWNJWpdwn1YFXhVs9nMWXwEBA8VELNSqVTc+BGA\n3taLe6zYGM719bXevXunWq0m6d6A2cc69AWlvVwuNRwOlUqlnBd4iAMTmBL4JZvNuoOJfXF3d6fR\naKTxeLyCuRMwZ//vCz7iOhiDQDVxBGVv1wvG5T7ks1LaTC4nKqcYSuMxA4PCy2azTjEkEgktFguH\nadr77Ot9eF57Ki+XS2dpz+dzLRYL9/8cJsAFyWTSQRN2Ac9mMx0dHbnFl8lknDLn3vsSoJ9SqeQW\n+r6uy+GD53BIaMRe++joyMU7WFeHUJCbhINrMpmo2+3q+vpa8/nceXqVSmXvBwlziXEEw4h1CEa7\nb8nlcjo5OdHd3Z0kOUsbK3symej29lY3NzeqVCo6PT11DCV0QhwhPoIxBOTE/rfjEASBMpmM21dx\n9z2fO9R6+ayUtnQ/mH6E97FYJxuTyWHgF4uFer2eksmkzs7ONJvNPprgfQvPslwunbImGERUnKAs\nkerBYLASqOp0Os59BvOv1WqxMMJthcVdq9WcK7kP95Rn5TDdxtp5rPgGwFNh6VaiYjhBEOj4+Fip\nVErZbHbvwVGUdiKRUD6fVz6fd4f/OjbPPu5ZLpdd4FmSo7+GYajZbKZ+v693797ppz/9qd68eaOj\noyOnULf1KKEOA7tB443a0xzWn2L+18lnpbT9TbTv66J8YGekUik3sd1u1zE8DmVt8BwcQljR8/nc\nuY8cKARv8AAImkpysIKNwlsPBeuV39kFue0Y8xlLS9yXoDjBOh8z5yhAMFHLQ4+67qdm5Eir9E4g\ni0Qi4fDdQ6xDxpv1BhQITHMIBgkxqSgPjfdcLBaaTqcuYH93d+csf8Yhag37QqwE77TT6bgcDtZE\nEAQr+PkubLFDymeltJ9CcrmcTk9PV5JiJK24VIeyOKxwv16vp06no0wm41xGXwHXajVls1n3bLPZ\nTJPJRLPZzF0PLBwlkMvlVK1WXVCXBfucFqhljTxWiQIt9Xo9ZbNZxwZ4Dsp5nYCNBkGgN2/eOE8D\nFtGhE0c4KO7u7tTr9SR9CMo/xDfepwDtFQoFFxiu1+uOyQXe7cOjm9YwSrvdbuvbb79VsVh0ewrD\nCPqqTaQ7NDwXV16UtifwhQeDga6urlZoZ1iwi8Xi4EobvK3b7er9+/fOCrHWp7WIqtWq+85kMlG/\n33c89sVioVarpXa77awSm3RkAy0cBFHJBE+5YLGM7+7uPrLid3kOkqXa7bYWi4XDrJ+T2+tLIpFw\n2bGJRGIFwwUeOKSgxIAnlsulqtXqQe/pC95vIpHQq1evVCgU3MGRSCR0d3e3skbiGB3s5cFgoOvr\na02nU1WrVae8wzBUv9/X1dWVFouF2xP7jGc9Rl6Utie44sAjYHl3d3fqdru6uLiQpIOyGJbLpSaT\niUajkZrNpq6urlwW43K5VK1Wi7SyrBsN0wJrlYxDvASUGJ4EDBqobVjyWBj7jH7Hkfl8rlarpWaz\nqXq9rlqt9igqF95FvV53kf2nfqfHCJ4WMYs4dL/HSi6XU6PRUBAEur29PRgks0lsABiGFwdtv9/X\nzc2NZrOZqtWqKpWKstnsxkC4TdaqVqv64Q9/6NLeYeMc2iB7rLwobU+gFVqljTuF0s5msy6r8RAC\nRt3r9dRsNnV5eeki6aSIRwmLGSvMLtBisbiCA3a7XZcyTHCzUqmoWq26A4mEnk9hjeIdfP311wqC\nwLnDj1XaHEiHCMgeUnzL+inmI5fLOXjkUyltSc7CJfiKdd3v9/XNN99oMBjozZs37nPslXUC9Fir\n1XR6erpinIDfP2d5UdqeQP+BVF8sFjUajVzQj7/vY/ECXfBjXcGjoyMVi0XV63WNRiMdHx/r9PR0\nI5bpQxmWEsmitIGb5XLp+O4wT4CAqHlChhluOsGpQysNWAw2weKxwtx+Tha2FC/AdggBaqB0Amuj\n3+873vpTrAPpnrM+nU7dugYWBC6JexBD4YVwwEFuqZ2FQkFnZ2cOjnlOh/yL0vbEnuhUvSPVnAj6\n3d3dXlwoFg9V/1gsRNKPjo50d3fnrP9arbZScS6usBCt64clDT6/XC7VbDbVarU0GAw0HA7d57LZ\nrEvg4dA49GbFYsLl3Yeifco0+F8EsRz/fD6v6XTqgpIPVbnct1jvE0w/m83q/PzccdeJUzx0HXjf\nKGNbjE36sE7K5bJLrLEK/TnIL5zSBg5AtrVSbDotSnswGLiTntKmo9HIWYG7Yoso7X6/r263654R\nazuTyahcLjsLHM5s3BN/UxAR7BuxvG8U293dncP0oVuBt9tEHhvU41774M2DNcJwecz1PpW1uk4s\ndEVswaZhHypdfBthDmGsSB9KDne7XaXT6RUWyaHG1ZYzaLfburq6UqFQULVadQld1ih5CEKzHpxN\nnPE/8ykyYOPKL6TSBgKwGz1usRsWAIG7crms29tbSR8W7HA4dPxOKn/tqrQJcPZ6PX377YdS5FjA\nLBp4sod27YPgQ/2VdDqtSqWi8XjsICG46bBS7u7uXJZiuVxWvV5fqZNCoOwxQnIH4/DU2YhPIcBi\nBJtZc1Sq+9RKG7FlI2AlFQoFZxwd8iC0KezX19f62c9+ppOTE7dObeamDVquE2IbWNif47p6Hqti\njwLl7e7uzrlM21h9nLqZTMZhudCAgElQ3ESz7Ukdhy/KYseCgFcNpmwphduc+BxWvO82GFwQBO59\nqWxIYhE/eBlk5kG5IuGD31G03qdJbbO54SgfHx/H/s5TiLWQbblUayBs857w6qFnUjTsUwT81glw\nIVa2PdCfwiOwDRqoQUOwEKs5rtj1CZPK1t72aX2W8usfUp8KantwtIMg+GuS/lVJV2EY/vPf/a4q\n6W9K+iVJP5f0J8Iw7B7wOWPLdDrVzc2NhsOh6vW66vX6zvQolBCTQ1YWyosC8XaT2SyyqHva4CCu\nXzab1evXr5VKpRxmvMvzcgDYgOYuAuzBnzZiXyqVNB6P1e/31e/3NRgMNJ/PXbAwmUy6ioiWhfOc\nMMHHCocthxtwmm3GEUfwniqViuNf22zc5yLEVKbTqXtHCnkRbziUxQqccXx8rEqlovPz85U98pg1\nZecRo2OdoQeDzGYZf6o1HWdl/HeS/gtJ/7353Z+T9HfCMPwrQRD8WUl//rvfbS0Wg95HIsdsNlO7\n3XZdR9gQ2y4q39VPJBIrJz7WNoXSOYnL5bK717pJ9S3tTCbj2iqVSiUXld92DObzuUajkXv2TZ1G\n/MPDzgEKhACNzQadzWaazWa6urrSdDrVcDjUcDh0759MJl11QlqFWTqVfa9PrcT9+jXIprHnoKXu\n+Wg0cgpkW+OA9UHQy2KzDx24/rzZ544zrv78b7oGz2P57cRi+P2hoBLW4vHxsarVqqbTqTvY4ozT\nJsEIw6Nk7PFsfaU9Ho9dzoOkT8YoeVBph2H4/wQfWopZ+S1Jv/7d3/+6pK+0o9LGNQzD0NHKHiNY\nK7iau56GFCkCX8zn8ytMj263uxKog7L3S7/0S45LvclaIhre7XZdyctCoeA4prs882g00tXVlTto\nNo2l7QI0HA41Go3cos3n8yoWix9lIdrU+Xq97qoJosToNRkEHxIfKGzP4qZ0K7UenkNasGUTzGaz\nB5MzpHuri+YVy+VSuVzuIwUYRzhgrZUeZ81yfyhwYLUo/zjvvVwundeEx4di9mmW1hPAmxsMBi6u\nc0irk7VnjQB7gOwqdh5Ho5GDgRhPGwcbj8dqNpuaz+cu7iDpk3hEu97xNAzDK0kKw/AyCILTXR9g\nNpup1+s5pYdrsmuXjFQq5YJiKO1dJtbS/lDcKCKULU2AbauwZDLpsvceqrs9nU7V6XQ0nU5dEahq\ntbrz4kdpJ5NJlyizTsBSSeVtNpsOPz89Pf2okSsKhaQdOLIoqfF4rJubG7VaLaes7fdggzQaDWed\nfWoIAMVFosZoNJKkjckZtuDQZDLRYDCQ9KEswDYKmzUuaSf4jmfu9/vuOo1GIza+a1O5r66uVrIK\npehOK+ytxWKh0WikwWCgQqGgxWJx8AM4kUioVCq5VP594Mm2Tg9Ku1QqucPXXp/SsBhqT91kxMq+\n7rpxtdqmvl96zStx4zn1YX3gpsTpEWeF7tlU69vVArCWIendWJMcNPw/tKOjoyO3cTYlhPB7agjT\nIQe2xK6LEUUKFh0lKCpS5KlR3Gq1HAZ9fHy80jLMfx7+bXnfZFTSBJn+l/YHxQ7XloMN+pUtyrNL\nMHVXwYq0GbD+u9o/bdlQXHeLsfrQQ1Rw+LFKx3o+Noi2zfe5BmvO1tjwPyvJlQeGSURjathEhwjM\n+dZ+InFf4956CXgZrKs4z4HnwF7Hu47i82cyGZVKJc3nc5dZu++16XdjX/vcO17/KgiCszAMr4Ig\nOJd0venDVmn7goKxWDFppfBzt1XaxWJxRfnvItD+UNqFQsHhxSjtarWqs7Mzl9JObYs4FeSCIHDd\nZmz51cfAQ1QoxKqNEhgmWOXv3r1Ts9l0rayo/jefz7e6N5xZOsiHYeiCtViEo9FIvV5vJTmJuiJ4\nNBarPLTCtorUekYElaNYL9bKog1dVGAKhQ0biINhX4oNZev3Idzm2rw32Y62+ce6e2LJt1qtFaX9\nlLRMLOROp6Nvv/1Wk8lEZ2dnOjk52apzEvMInMoc8f7W2saQ4YCIk8izrfgG7WO7sQff/SD/m6R/\nR9J/IunflvS/7vCMku4j07ipNk3VBjjiyr42u7VC6JQxHo/VarWc5YhiI1uxVqutTGjUBvJP72Qy\n6QKSbKJdBd60tH4DW6sJPJJOOWCaHJZxxFqgvnVvg3NYQMPhUIPBwCUo4WrDOGH8SDKx1t82ypw4\nA8HRTe/DO9B9vN/vr3gA9vs2WLhurmzt7k6ns5KMYlOn7b23FaxDYDVpu+axFu4C4rAp3f774DFw\nCAFxkfQC1mv7tj4kNqfCrqM432ceLN9627Hcxqhj/vCu9hWEtF6ZLUW86bniUP7+B0lfSqoHQfCN\npP9I0l+W9D8HQfDvSfpa0p/Y9aFRHgTmnpuk02lVq1Utl0tXrpHsSNgadL8AHoiL77HwLNPjMdaK\nve+667Ap8vm8Xr16pVKp5A4hnr1cLu+lVjNJGXhN9L1kHKfTqXq9nlqtlkuVLxaLyufzrrM2igT4\nJG5GKJ7bcrl8MLYATk2AudvtqlqtupZW2/YExRIcj8d6+/atfvaznymXy+n169eu1+hjMWD2jVXU\n2ygu1oGtbGcPRisoFOBBgtb1el2TyUQXFxeaTCYrnO0442XL7/I8PsMoSjBuaL48n8/dmjkUzsx8\nMU77DLyirIEVWedrn+WhC4Zh+G+s+a9/adeHtMJpB5UG5RH39LRWgG23tS9XjXogkly9BfBaWAeT\nycQpwm1k3+6/HUsWAeNnF5kNBNoAmsU597H42cTEF+CR53I5l+XW6XTU7/ed18Kz2wJBKO3j42NX\nO9la31HPihK2XX/WCWNFbYvb21s3NmDX24rtjnJzc6N8Pu+Sl/bRIuyxHqWFhuLU64AhhKeE0iQo\nT6AQVsdDhyQKG8ooXpVNytr07kEQuNiR9aYOBakdCq7z6bQYrpu8pmfD4CeAaCctDthvG+/CwoBS\nti9BMfhukb2vDV59aiFIwwFog7qItfKlVfxu3/QtrmUxXUpiNptNxwggLmCLZdF53s6BVeIwe3zB\nMry7u1vLqLAJTsRTMB4Yr10TOBjzcrms8/Nz9/y2nrkdm+cslmVDnMJ6IGTEUo1yUyCc67FGr66u\ndHl56eAx8hQeEtavtX4PEQh9CrGMpOl06jKw18mzU9rbinXbyFB8bEDPirVG/OJIFFIibZ5gxj4W\nz0PW3abrW9iG55a0oqSfItBnn9XCNhx8xWLRwSBgebbeChCDz38meAY/2FrR3ItNwLxEFRFDLJwh\naYWvvAuMQUArnU47pb1cLldcbMsFjvr+cxMLIU0mE9csg4OU4DYZwZsOJXtQNptNvXv3zpVDIL18\nk/j4t58kxdg+RyUeNd/WeIhar748G6W9qxDEgzMLe2SfgtVfKpXcBpxMJi45ZTAYqNVqOTcYnviu\n4te22BZH4/m63a5LsT89PdXZ2dlBqErbCvSyIAhUqVSUTqfV7XbVbrc1Ho9dhL5QKKhSqThvCvyT\nTTkej3V5eanr62s3XljrHA5YzJZ2Z8UqF5Qs9wYj3Xa8sAKhYHJ/lFImk1mpprhvjHTfwtjk83md\nnZ25MYJ1kUqlHBRFajvGzTrohQOaLMdarbZShndbsTTA8Xjs+oB+6lwAX3wKKGtFkjsIH4KXntcb\n7SBEtAlw0WljX2It7XK5rFevXjmOM9mRVmlLejCjLo6A7dqIMlDHQ4IV0+12HVMjlUqpVqvFCvQ8\nhfAuHLKLxUKXl5eOVklNjkajscLzHo/HLnsRDHowGLhGDtVqVY1GQ5VKxVnyqVRKi8ViLdTBoZhO\np103k8fS8yyUQxKStagspfI5HKSbhEOFYJ+1ZEm4oVIhhdTYA1FK0zJXKpWKixvl8/mtg77SKnxD\nQ95arfYsErh8Yf4tvGPZSGS0blp3z+uNdhCCTFjXD6Vv7yIobmpsg+fRwYYMwFar5XjO0u7YMK7m\ncDh0gc58Pq9qtRpvUg1XneL15XL52RRusu6tdF+GleJes9lMzWbTBaas9WELWE2nU1cMHy44uPRg\nMHBKAOYJVjhBL8YROhcp/I9VonZ8UUDWEmy1Wi4LeLFYqFarqVqtOgt1k9IiaGUpjcAU/rj6gsLg\nB2OA76/77qbrMo5Y1tPp1FEAq9XqCk3ThzWARNnDm6iyDwlxj2w2u1LC4jmIpfX1+321220XuLWN\nFuK+9y+E0ubEJ7vpUEqbw4EaIWRHUjyn3W67xJTHBEZQOmQP9no9NRoNt7AfskSwYGBsADfsq23X\nPoUxwvUOgkAXFxdqtVrOAiG9GgWNwrq7u3O1v9+/f7/i+aAU+E42m1W1WlW1WnVYOGuHbDcCoIcY\nI9gS/X5f7969c887m830gx/8QGEYqlarPehN4VkSAA/DcIVX/9Cz811+oGPuGuNA6XMwjkYjdygx\nr1HVDy3RwJab2GXPsD85fJ9jDXa8gV6vp7dv3yqZTOr169fuGbd51s9eaTPRuBdMoBUf6Me6iuM6\nWWsQpU1zBPBX3DI2P1FwWBH2OnGFZ7aWEEEX0t5t0SW72NkINmMOi+c5Km3pPk347u5Ow+HQWdLX\n19fOkoPiBc0LNsxisXApxhS/wgWliXGn03H1MmAqWAWN1QoDyR6Q+xo3FBNzCS+81+tpOBw6nHiT\n2CQ0Cq2RzRmHHmsrFI7H4xVPZJd6P+w1mDx3d3crY93v911WMeJb3PsQCzewJ7a9tvViEAyHTd4L\n8B37cdMBajtE2Zrk28hnr7Sl1Sw/+29plcdNsBLmwraDxeldqVRUr9ddlTVStamUlslk9OrVK/f5\nXSwHLKBsNut6Q1L3YTgcOr4zTRrsSW3HA0X/HBW2FQp0kch0dHSkTqejy8tLp+jAqW19FvjVlBqg\nSQWYMckf19fX6na7ri4zmCfjYlkHiUTCfSZqfHcRCwecn5+75x8Oh+6wiNN71FZnRGnbCoMPzbFV\n2ty7WCzuXKANOTo6Ur1eVxAE7l2AgqQPjJynsHxtYG9bAeqczWbud9Ti2TQ2Np6GoRZ1YGAsso9h\nLW2byPbZK+04lqxV2t1uNxbuHUUj4tQtFAqq1+tOWUOvm81mur6+dpscFol11eJsDCxLcFa8iGTy\nQ61qLBmqCbJI7Fg8ZwUdJbwDCx+rGUZCs9l0ix6L1XpPbC42C91IUHLMUyKRcFamn11pFRfNYjl0\n+dyu48ozcwgnEglXXW5bloplnezS4cYyVvZl6UKPBNqDtdTr9ZTNZh1keAjjwV7vsawt1hNiC3Kt\nE4gQeHZcK+q5jo6OXLNwv0cr33tIPnulHUfYvOCdVKJ7SIAW/DZeVPMbj8fqdrsajUaO8tTv93Vx\nceGYA6enp64mSdwFxT1Y4IlEwgWxsD77/b6SyQ81hp8Tdrer+F2B7u7ulM/n9cUXX+ju7k7NZtPV\nfQjD8CPsmUxGsFqU9ng81mw2W6n1QbDMWtm4xTY4WS6XV5q/7kPhYDCUy2V98cUX7u/lctnhv5sE\nj8TWfo7brd6uK4LqXOex72aD9TT0AKrCK5D07LBmKxZmReJ4ysRObAB7XUCXyp62hkkymXT66BdG\nadvoK+IPykOWNtjTeDxWKpVa6QsX9V1rpZGyToQ6nU67ugu3t7fq9XrO1en3++4eYGuU7rSWzabn\ntZgqwuI8l3FMAAAgAElEQVTv9XpqNpvq9Xqq1+srVd4+Z0Fpj0Yjl81ZKBRUq9X0/v1711wZa5pF\nDxOi2+26Yl4csjbLzCoKDod1hZASiYTK5bL6/f6KQvPhtF3iFdZzgg5oW9Q9ZPmyrnYJtqO091FX\nJurarHVYHJeXlxoMBi75jf3zWK/lULJOaT8kzIefQet769I93ILYxC7W4oP3i/1Gn1DgtdpMIUvb\nekgsnnhycuImh5TRKGzbcr+bzaY6nc5KmdZCoaBqtarvfe97kqR37965jLr5fK5er6eLiwsXSCTK\nj8W9LYYIO6Zer0v6gKOdnp4epETkcxCghGKxqNls5pRws9nUcDh0ViJV9KhhYWERq7j9a/vCYYAC\nPT4+Vrfb1XK5dGwhmyVpFe8uygdrnsNg13T55ya8z9HRkSqVivMSO52OmxvgoOe2bnl2uz7iWtpg\n9r7HggeHB+grZdojdjod95mHjLDnNWprBGgDK0qScxGlh09sBhKMGIsKFsa6gkPj8Vjtdls///nP\n9fbtW9XrdTUaDX3xxRcuUMX9bQVAsDyuD8kfCyTOM/vCwiAzk3Kq23ab/1wEpV2pVByf+Pr6WtfX\n144tkk6n3YK32ZJWadtEEMQPVpG9CAOiWCy6sqrD4dBluXLoMu52DW4rxDqeIw3zMcLYkg2az+d1\ndXWlVqvlincdsrDTYyTKm4ojPk8esRg5RoVfo2g0Gunt27f69ttvnZf5kLUdpzTrG31o6nsmaSnp\nvw7D8D8PnrAjO225+v2+60nI5rIdKzbhcha7pFYIBPdkMrnSJ476B7h7pVJJjUbDKW3bPzGfz6tc\nLrv2XgS5bKnP9+/fu9N2Op06ihWuPVQhLLd1WWQ2g4rAqFVIBLbsNffhDlur1fd4cPftzy7CRpfk\n0r5JR4cGB8eYLvC43Sx0W4yJsbXJJ+vEh0iwBim1C2RCASpbtArFy79JU39IdqWCPnextFMUWaFQ\ncFYm84bn4veF/ZTjAZfectl9qxd6JU1OLNSD4cA+h5xADKXT6XxUV+Tu7k7tdnslRvWgZR/jXeaS\n/kwYhv8wCIKCpH8QBMHflvTvak8d2R+S6XSqVqul29tbDQYDl1RRrVZVr9ddAOQhahYKm9Ru6R4/\nbrfbajabTknD0S0Wiw6GoNEBFlYYhs46I3261Wq5gwWYxHoKs9nMWWzwO2lfZQ+gKEFhWyvFTvB4\nPHbBOCxB3uUxQjyA1HHbqIJFjMX/GKXNZoDTy6aHRml5tBcXF2q32x/xan1OPteO835hGLpNVq1W\ndX5+rlQq5TDHwWCg8Xi8wt5g/eRyORWLRRe8fJF7yinB8k6n4xTX8fGxi1kcKqFpW4EDPx6P1ev1\nVvpvItBSgefsXpzP564FWqfTUa/Xc0bczc2Nbm5uHBXVv24QBKrX66rX6w9mhcapp30p6fK7vw+C\nIPgnkt5ojx3Zvft9VKnL1vJlIODnQsGL6rghfUwHsjUhGOTb21tdXFzo8vLSTYrNIJzNZisp1Jyy\nWHH5fF4nJyeuS7Wt/IdlyCRNp1OHidv60tS1JsnBf/44tCbbJR5l/ZggpeWSsohZhFyXqnxY9Lbj\njN/jk3mNerdN9DPmrFAouDGl5ghjaL/P2mE9WIrguvGwNWySyaSjZJFaznvY8qpYZbb6HUFOxsPP\n9NvVwrbBeBtA/xwsdvZOEASOH55IJNTpdNyY2SQWxtlWWTwEnGIJCpa5NBwOXdKTL36WMWUiKGXR\n6/Vc8TOQAXQXlR6tsifmdXR0pJOTk5W6N+tkKwAnCIIfSPpVSb8r6SzcU0d2X2yRJLvZsKCo+TEa\njVQsFnVycvJR9/AowaIFW8bqvr6+1vv373VxcaHj42O12+2VVlOSnMVg2Rosrlwup/Pzcwd5DIdD\nd9hg8Q0GA9f9BnyU9ymVSq5a2mMK5MNtXiwWK3S1XQXLg47d19fXrhaKtbRtU16yRskcLRaLK8qU\nufWj7HGUDsEtuwaurq7U6/U+qidiMw9RCBZCWfe+k8nEzeFkMnFBSSxpmERYZGxyChU1m00XMK7X\n6yvlS3fNrrQKmzUlaeV6z1Fp2/m2nVk4/MMwVLfbVbPZXFlD7KlyueziUIdS2iSrtVotB8EOBgOH\nQfuC3hiPx64mfKvVcj8wu1g/zF0ul9OrV6+cwYauYn1SeoJ6LXtR2t9BI39L0p/+zuL2V/5eeGdk\nh9HCy+8TCeyAlQynNw71DRcclz6ZTKrVaun6+lrNZlPtdluZTEbT6dR9Dqv8+PjYbWhr6YDFVioV\nZTIZV7hIkmuO4Ctvylfadzo6OnKntk1E2IZlYqPfBNYeE6G37mK73dbl5aWDD+yYWqWUyWQcFREv\nxL4nOJ+tDxH3YGEzA48NBgMHkTBeXM96RSg123HIUj6tAFmxaW3HGUkOQuEz4O/wwVkjVlljNcL0\nsYktFhPdNM8oPixVOL821f45ifVEONiAJTnkgJ263a7zTPDOSqWSpPuSDFEZv7s+F4KX1uv1dH19\n7eDX4XDodJAv4/HYfQ+4jgA5it9+j/kvl8uuMBg0T9/AwJh7aD/E2tFBEKT0QWH/jTAMaeIbuyP7\nj0w39i+9jsO+wLm9vr52DI11G2xbsdYXCTYcEtJqo10waAad36G0fTcfrubJyYmzhPr9/kpRc7BX\nNrbltgI7UIMCpSvFt0SLxaLevHmjMAxd66fH0qps2jQL1lLo+DcKCG+Gw8fKbDbTzc2Nut3uR4Hk\nbTwCFjoKmnecz+crVsvp6alKpZILQuO6kvSxKcGKFGxbcAqx9V4wLEqlkkt/5rC7ublx8059Z+bE\nr2z30PszB3iFqVRK5+fnz7oEKZ5ss9l0RlG323WBegKT4/H4I0gNS5wqiMBT+/IowjDUaDRyuub6\n+lqdTselsZPR6R+m1BkCinz79q2zztEZx8fHqtfrztu1HgR1iaKKZP29v/f39Du/8zsPPnvcmf5v\nJf3jMAz/M/O72B3ZrdJ+SKDLXVxcSJLrFr4vpY31Kt2nqLLZwJNtcMvimChtn5JjraZ6ve4s7vfv\n37v6EChuy9tE8eAxDAYD9Xo9l8IehedtWrT5fH4lIPjYzDPLqrBW5CZKUir1oSwsStvO22w2U6vV\n0uXlpbPGoyypuMJ7cqjO53OHP5dKJddINwg+pBff3Ny4zW8P06i1NZlM1G63lcvlVKvVVjawTZAB\nNgHnZJ28f/9eNzc3DtPM5XKaTCYu0IxnhTw0x8xBu93W27dvnfdnXe3nJHgFWLHffvutq5ljWTp4\nKD73HUMqCO5LOkiPa3yNWFjk9vZWNzc3ur29Vb/fX2EgRcVfiKURULXBcTuvX3zxhV6/fu2C63gY\n9AjFULHv85u/+Zv6zd/8Tffvv/SX/lLk88eh/P0RSf+mpH8UBMH/qw8wyF/QB2X9PwV76MhuhU1M\nd4yHqHz7EpQjm3PTZzY9iw0sYC3bheozHcBPwYu73a5ub29XyohSbvIhi8wG3/YxXjZAuA/s1LI6\nsNwLhULsA5kDhHR+mDoWywYqANYCPuC5bXYqJQiiLG4LZQFn+X02EevBheGH4lzEWSw8xrtzAAI1\ngf9vCkBxDw6jTCbjyiM8R6UNPEKg0Vqv0mpNbf87YRhqOByq2Wy6WBI5EftQ2hzww+FQ7XZbvV5v\npViXXUsoeKuggX1Q8HiLpVLJ0YNfvXqlSqXi4MWLiwu9f//eMZJQ8Lu8Txz2yO9IWnflvXRktwJc\nQCfshyKp+7onf25S2D4DIEqwFiyrwn7HnuD8ibvebrd1c3PjaIZEkyW5GtBxlfa+hHvuYw5Q2hZu\niVPZzv8+lo5V2ojli9smClimcK/ZhGDYvhDxx/Vl/KMUpO/ZcK9Go+GeGzcc15r3gEJIuvw6owCP\nolwuKwgC12Vnm5o2TymwMjYpbcsWsTkAWOG0ZDs9PXWlT7eJ8ax7LpvwYlkedh0ynzyzLWlha9tI\ncnRf9myj0XC4NZDQ5eWlfvKTn2g2m6ler6/kemwrnxwIswqMgYHeJWmF2nUIiQoI+bLLIrGuu2Wb\nWBaD74pZTBR2zGAwULfbdV1YONUJlForM86hsu077FMh0EJssVg4D4LGFShPYAtJH2HJ0seMBJ7T\ndqchOarVaimRSKharapcLjsrnPR4AmJRYoOw/X7fwRD2eTaNDWPH3GYyGVcO2G8CzZqg76ilLFq6\nIXCMDbY+xwCktBoLWddc2admAmNh0RKotHWnbeGvXdYmOHq73Va73XaQDVCdXUfZbFadTscFu32s\nm3kol8s6PT11xeEoH8z1KJ/xgx/8QGdnZ8rn848yRj+50pZWFTZKO5/Pr1g6++z7aMWe+CykfV3X\nLkhcQd7RWhXS/RiwMMBU2+22rq+vXXCSBYKVhdJDIR0CStrX9WCWkEhkOe/UJacwliT32bjXxrs5\nPj7WfD7X7e2t4wDbMrckRPV6vbUBPJQ2wTSs7bjiHy7JZFKlUslRPW09ChgojAEZrTSGIAeBeaa+\n8769qn2JHwvhIIraW9bQwLqW7scfCIlxemzZBhsza7VaDh4j54KAcaVSUblc1nK5XCmTgPVvFXyl\nUtH5+bmzoG2Mhrn63ve+p3w+7yCUdXklceSTK21OVZq0jkYjd8phqfru+b4UKynSWH9kSfpiOeJ+\nGvc6sXQei5VZy966gvZ7LF7rRrNAGKNut+sUH4oKOMbykx+CVJ5S8KCgdvl0PPitKK043pX1VLCA\nbLARq4pMS4rU+0kO666L4gbKsRayrzislQlljB8/eGuVNtRByhBQV4Y6J/Q/9YPSccXPc2Bc7XvY\n9fIYsYcdRhecel8sZOgbOewD2GQXFxcqlUqaTqcrzT/iKnDWh4VF6JAUhuEKnGbzLWxAHUVt4yUE\nSWnZRlKdpcFieLA/Hwv7PgulTW2Rt2/fqtls6vXr13r9+rVzp4MgWMnCs38+RoGnUikXLKAGgF/Q\nhfvYjLk49Tx8RWyDmNYltkWNLLvF56CPx2Mlk0kHlwCPWFI+pzjBKbjBz0Vps+j9RgbQwyjQhMKK\nI76HwvtmMhnnyrZaLU0mE52fnzvoJO66wS3G2oMTvmlMrQvearXUbrcjPUVwdcYCy5SNXqlUHF/5\nsYJxBLU0ignDQfoYsQYYcYd1SjtKbKYgz317e6vJZKJ6va5areZwYwy7OMrPHiZQaynHwHqxCXqt\nVstxy6fTqWOx2LIN7C8gK64ryXmT9JQldwJD9DEe8bNQ2jZNvdvtuvKjDCQLWfo4kIdFSplVazWs\nEwYLS7tarbpehL5YK45SrUzUJvGvZV1AlBXKg0XDxgmCwHXYsckg4NwUl2HT1Wo1dbtdVSoVVSoV\nV0rU0ov85JNPgYVGpar7ChTFHod77Ef2GXPbAJiDdjgcOqsIF9eOxToDAEUHbENi0Kb1tVgsXGNm\nfrZpukGDWuqePFawWGezmVOk7BMbNMeCtSnl21iyvAN10VF6Dx2S/vUJOCKUUMC4Yo0wVli0Dx2k\nQF3D4dB5TlD1+C6eNAcue9PCb8SU+B18bHpish6B5SxbZB/yyZW2TQWn48XJyYmLrtoFZIVNNhqN\n1Gw23WKJm1Vk728XaJSw+QeDgW5vb3V0dPRgIaY48AnKIp/POwyNIIbljvb7fReFB1JBSVFCdDKZ\nqNVquUVFoA/rG/ohEMFzCWAx5oVCwXWpQZHEwbNhAnDogUmWy2VXX+b6+tpRuy4uLpyVZKvMYan7\nAsRydHTkrK51LBLp/iChKzlV7eIG0jnEbZD6sWJhgffv3+tnP/uZg5E44CzeykHvF/WPI5bSaWlx\n24qFTiynezAYuENnMBi4uM5DTZHZv61Wy+0noBH292KxcPQ/gpMk+FlDCCgSS5sfci8IjO+af/CQ\nfHKljcWTzWZ1cnLiypzaTua+K2EXwWg00u3trbMkSJ+O29nDwhL+tfl/LHpqFJTL5UgYJe79/L9n\ns1nV63Wdn5+r0Wis1F24vb1VOp12LAeoSTbQRZYWQoYeY1mpVJyyrtVqH3G5D82D98fUYqz8Hwvf\nwkhxrsuGs0q7VCq5QK2dNxRorVZzdUE4zLiOL3g5mUzG1ZNAYa+jnxEfabfbKxZdXMF7AH+2BbG4\n3zbzxfodj8e6urrS7//+7ztr1SpsSgvTw1KKbhix6T5AVVGNitcp76g9YT/rZ+V2u10HqeE58T7r\ncH9aATabzY9wdvYQnyFDEyv6zZs3Kx6sTbkHhiNdHw8AxX6ITNVPrrSxtEnrnM/nDypcW5NjNBrp\n+vrabQwbuNlGLFzxqXivHGCkwbJoGo2Gq9uAtY2rS2aWDWiygHDtyezLZrMr/QixNIvFogukHEqB\nYzHx7DAyrNdAYhUb5KFnYbw4pK0CwlObz+c6OTmRJHfPXq+nZDLpqjLGieRTxgCYhXVyiPXCvTqd\njr7++mvXxJkyprswD6wnaamI3Au3fjweO68ODDnOvdg/tMRrt9uRtTu2FXuAEcjGGIF1Q+XPZrPp\nvAUgDxQ+9E680ijqKHuINVgul50hBSuEQL+dA3QYtbDDMHQQyi+k0iaSDyd10yaI4iKPRiPn0iST\nHzqg78Lp9i2/T6G4GQtO8Vqt5goXEUDCghkMBvrmm29cZp09dIh8j0YjdTodF0QhxbZQKLjaz7Va\nTWdnZytlMPf9/hZ7RvFdXV3p8vLSWSnAVFQ5i5s0AuaImw8khKe2WCx0cnKibDarr7/+2tUDse8Z\nh+9ssVpKKxzqgCOYd3d3p9FopMvLS/2hP/SHVtqTbSP2XX2Plb2CYut2uyt1d8rlcqx7WCsbpU37\nPf9z/nM9dF08Dqu0q9WqwjBcaYixXC5dtihGoKVSdrtdV19EurfgwcrByCld8OrVK52dnTnv18K1\ndr1g7LDu7FgfYn08C6Vt/4wSGzCx6cKSnMIvFouq1+suEymuoKhtIoDlPH8KsWNhqVhBELiACtQw\nNrJPIWTBYEWAL6IQoGN1u12XOo8VjoJnIz5GYL6wuQjWsIFQ2pZRAy2Q+MSmcbLwlk+pZPxIcKjV\nah91FYGS99BBD+TR6/VUKpXcujmUV8K4EPymXnscuqkveBOUjH3z5o3z2izUJt3X1qCQ03Q6XWH7\nPPTcNlXfPqtPN/SDneuEvQ/7AkjHZqgeHR25kgSUhLDlj+2cM+82uxFPz1rY+Xxei8XC9W60uDm4\nth/83JWSua18cqUdRyyRHaWNVQmWycl4enq6dadqi5mBXx7K9Y0r1n2zC566G1hEtjg/+CfBLBS5\nZeiQ5TcYDNTpdJTJZHR1daViseiolgREKZT12HcAwrq5uVGr1XKekbVyLOOHanh4TpvEp1JG/T9j\n1Gg0dHR05OpAkFKOgtkkQAe9Xm+lSuMhxGL1rEmaFu8S2LNsi5OTE9dJhS5H9j2wlkej0YqCeyjl\nOooLztqxHGmsXBu/eOjZ/VZuBNQ52HO5nHtuDhoaQsNEsUqbAxFlzj3y+byzrMHPgY0gC1SrVYf5\nP7Ze/a7yWShtLKVSqaRut+sUlM0c86tn7SL7dGd2vQ6bFTjEFmS3lQDZxLjLvsuPK+cHtbAu2EDw\nS8GXZ7OZK1YF7r2LdSfJYde2/CVlCXhWnguvYBvrl3d96P/5oQAZnoa1CH1l6F/XPts29VJ2EZSZ\nTf7hENsVkgH7J1A7GAzWsrJQ2nhFHHrbYNv2sPcDz5YjTikGFKkdA75rk8QYF+t5B0HgqJG2Nki/\n33frCkucA5eEGSiDlqOOYUOKOwocajH7CA72OobboeSzUdqVSkWz2UzNZtOVVMU6YpHvsqjtBrHR\n58dOwC6b2gaG6IICfEEJS358RgKbwKY6E6ix9DFbgN7eD8uo2+26oFej0dDJycnKWG8jBIcohNVu\nt1fcUcYZjNZu1F2pYpsE5VOr1dx9gSAeCkJHWZCHEqCIVCrlaGYkkzwmk86u9XVKJgxDt7bodWit\n3F3v6+9RSzc8Pj520MYmholvVHFN+rfm83kXSOV6QJ5wvVnri8VihbrHAdntdl2tI1uZ0zcohsOh\nTk5OHKxCuvpTSJzSrEeS/m9Jme8+/7fCMPxx8ITd2OFxg3XaBWcnc1cc2p76NsD0mEmIG2ThTzYL\nncVvb291eXnpetX5lcXsffgd7277NHJt20ElkUi4Q4DUbKxsDojRaOSsF+obb8MbhldLMwGaD9hA\nbxiGkfPlB4URntEfCzwLDiquzWZj41oLr1qtrlC8RqPRSrEmfx59vJYsuXUH/GPWD643GDQHaDab\nde+3jdi9YvH/dc/IekD5wVjaJDYtP6oMsW9ZExDHm4PCF1XWwUoUYYBrwtjgOihgvD0bsCSzFaUN\njALrKmpMrMEE9EKdG+JL1js6lBKPU5p1GgTBvxiG4SgIgqSk3wmC4P+Q9K/pibqxP4XYbEHp8QO+\njXKzGaEoF4qzW8w16ppRHGhrPbMxgZBIYrK1hHH92AxE/cEhqXkSFyaxlgnvZWt2SLspNVtEi8NN\nksO+G42Go3vZhBJaSTG/NmHi9PRUYRjq8vLSpSCvMwDsPLXbbZVKpcjsUns47GJEYD1SoveLL774\nqN7GcxM6udjkFZ+JhbFFI2wojHCdsYzXeVk2CSYqEIwCl+Ss5/l87p7LKmRr6NlD/iEhtoFVns1m\nXekFIFzqtR9KYsEjYRhSSenou++EOlA39sfIYyL6cTeZjbbb1OltntG/luXKomzgYG+j/PnT5z4n\nEgnXSIE2X6PRyHktWBm4hFimUNyo1+HLOvfa4vJg8aT1PgbygLsM15Z3tErbBlChRn777bf6+c9/\n7rDQH/zgB67BxMnJiYOFbODMpz/aYBpKm3TzKMGq3AXrxIIrlUo6OTnRmzdvdh6zdbJvxc9Y9/t9\nZ51HGUF2rs7OztwYkQCFNxO1Tvg/a8lbJhmemx13vEfyGdAP1kOKst4R/zlgby2XS1elknW1XC6d\n5X5IEkPcHpEJSf9A0i9L+i/DMPy94Lv+kNL+u7FvI7g6RIOpuxuHy2pxNjA2G6SIuhfc2V6vpyC4\nLyKzywShJMlmJECHqxhXwdkkARYLuKVlcEj39VYKhYK+//3vq9FouE7S7Xbb0fDsu8IwYKxQaFEL\nE9z89vZ2hc3CYrZ1VLbFhjncrOeBxWQrtK2DXGCq4O5TQ4ZelUdHR+4zHDJ8l3HmULMFh6ww9uVy\nWa9fv9bFxcValztKwEjr9bqrvbwv4YCDcWXps4+NH2Bp2tKk62AjcjIYcw4/aHZRAWg8wGazuZLZ\ny1xbg4N2b+/evdP19bUrNud7Kewz2zeW5BnExo/sGFFfJggC57Xx3cdCqw9JXEt7KelfCIKgJOl/\nCYLgn9PH3dcPF07fID6diJTfuGKxNjbtOhjA0u4o6CTt3t0F3NDWVbaZXHHFuo0oG57JQh50mWeR\nnZ+fS5Kur691dXXlmCR2TG1VO79FUtT7ckDYHn/QtIIgcFlyuwT0bMU9H9Mmq9Zi2r74SpsDDKVN\nSU6f6WDfjYODwyzqHVDaYKQ3Nzex3o+DEaV9enq6V6XNs1mlnUzGK4H7kKTTaefFkQkYdaBZ5Qjk\nQyGvXC7nqHn+IcdYzmYzVSoVV86WQ4fvgWG/e/dO33zzjbrdrjMcMOast4zSxjr3i8ENh8OVQD6C\n0p5MJo5+yN44NFd7K/ZIGIa9IAi+kvRHtUU39t/+7d92wY0vv/xSv/Ebv7G3lGlrEXY6HZcJFSfS\nzWZn0ZBlhYXovftKS6LhcKjT01O9efPGWS+7ZKqh7H3IhfuwoNhk1mLkELGHBi6iv3BYeCRrYG3n\ncjk1Gg0XtFwul87ixpK0iswyPvzEAoTPw3wg7TiZTLokm16vp16v99Fm8INlvtjP87xRhyxucqFQ\n0OvXr5VKpVxX8DAMNRgMVkrXcijZqn9c13elGXfLLPCtK+4v3R8Wdl42rXtLa9unAsCKL5fL6nQ6\nyufzbk0/VnHbZ2at+sFI2/gWZW2zDOMWbuPAB8ajVEOn01kJfvf7fRfX4aCywXnmnHnBcMMDyGQy\nDrKJCo7zeyiBHOK7QiNfffWVvvrqqwc/F4c90pB0F4ZhNwiCrKR/WdJf1hbd2P/iX/yLjlucy+U+\nasb6GGFhDIdDdTodpyjidBnBrSYFtV6vO26xLyhtaitAicJSYwFsI1bZ+ooBgUWAVQL8QPEilLZV\n9FHjyoKjeTAlaalZbgvtJ5NJx0dmYbIY/fTddYoV+KFWq+n09NQ1NKXkJe9hFa5V2HEPdDay776y\nCYvFoqsc+U//6T91eCT8Yzv+NkUZRbaOy4wRYrFVP8gaBIEzKkjDjrPmbZDsEEo7nU6r3W47itw+\nukKxbqzilrSitC1rxKfabWKzIDbRjEA3RaDevXuni4sLN9bAGuxx+1ysE4qFcW1LQyyXyyqVSlou\nl65zlm8csC+m06kGg4GKxeIKbLetfPnll/ryyy/dv3/84x9Hfi6Olnkl6a9/h2snJP3NMAz/9yAI\nfldbdGP3cVfrosRV3n4Q0DISwLPWuaxRYu/LhPnWjb0nYutdrNuI695nnTVmIQhbfY50XBQ3ViKK\nG+Vto+72mX2FyKGEpWt7TtbrdacEJ5OJEonESg89a5FZRecrWDZHpVLRycmJTk5OXE0RDhfgJZ6T\na9mSqWwwrCtbe8VP2Qcuse+LEuaa9XpdvV7vo3mzJV1hB9gx9PMBsO7gBGPFWY+J79vgWVxL21+b\njxXfk7GHE/eJgpNgyrDGiBf4RoZ0D13ZHp++d0Zjh3K57BKdGI+ow9p/Jq5HzATPzeY02HVkSzzY\ntco4UFwMY8t6zECXxGN4L1+3YGn3+32Vy2UXRN1VcceROJS/fyTp1yJ+31LMbuw2UGQXN3jpNjCJ\n3UhYQodMJUVpLBYLtxCq1aoLFFHrxH+GOIEd3zqzWF+j0XA9Em0NX/BpmiFQ47vZbH5UttW674w7\n7AfcY34PRJRIJNz7plIpXV9fu03ItbBgohRQIpFw3sfJyYnOz89dPRNJyuVyuru7c93HrVUJLbFY\nLByP0bMAACAASURBVKpUKjmIC0uGBAlcURS3pI+sIF+CIFCpVNLr169XsmgJjlLOleqJfMdadrBS\nwOs5POH5JhKJlQxU685jaR9yMz8kFtqxweB1QWFq1RNkBBO2GZLWaELB20Ax70vfV3jnKG3GmMPE\n1wU+FLZcfuhExEEPl3w0GimRSDhcnetizKFrpPsDAhYL8QxJzgDqdruuuBhcbAwGX/C+yVKOs/cf\nI0+SEYnS5tS1gTMCSHFdRzt5ltZ2SLEWHPS5s7MznZycuC7dUVzdqO9b8b/Dwq5Wqzo7O3PtsTjs\nsMqJkBcKBQflYBVh7fheCZvSwknwTFnkuKw22xIr0VrzklZgGXvwJhIJZ1HZWt5ADngQjBnj5Aeo\n8vm820jW4sPajnJVNwmWlf23tcaoYd5ut1cOUja+PVzwPLC2qfpHYMum4VvLP85zHkpQ1nSTabfb\nLpC2rkkDSoh5oWuPbaCM0QSjiuQs23HJZkEC86HopXvYw2Zq+rEUC0lR/4XPhWHokqvI5sXDgTXF\nQSvde0xU8yuXy66mun0HulRZ3rU/fxhC/ro85Dw/idLGimLBEwzr9/uu+UGxWNxLYHLfggWA+Nle\n6zwFayGw4LjeusOJcqyvXr1SvV5XuVxeCdKwcBjLZDLp2mpJcinjMCN4PoIuVnHY+iZYDyxmyywB\ngsKS99/JjgVjhdXuK+eHLGFYPCgG3oENaDm6WG+8o3Xd112fMgUI47pcLj9qccYc2bok/rxZXJuY\nR6vVUqfTWYFCKI702N6Auwr472g00tu3b/XNN984iqf1WnyBJQMHG88MqIma75lMxtWXockAMRG8\nMiAHWzaAJK4wDFe6D/mxAN8joPaH7dFojYRKpeISajAuuI89HGwfTpuUQ8s1SU5f2cbO6+bwqeb1\nSZV2KpVylKtOp+Oqy4HZ8tmHxA6OxeT8H/+zj3l+a3VZuppV6lEuprV2+XzUpANRoLStm+cLyg3r\nAI/Dp9v517diqWs2fTsIAscqASpho9kEFDYPSs+6wVjvZPD5MYIosRi5Ld7D+FmlbQ9MmxodR2lH\nsYoWi4WD76zHh1fIAWUPXBS6taxIiqI0KGNIsGufOPU2wrodjUa6uLjQT37yE0efi2MZDodDNZvN\nFWX3xRdfaDabucYAvV5vRWlbaxuaIVX4ovIaKAtgreyogl4W4mGtVCoVvXnzRq9fv3bQ2sXFhePT\n+3x7G8egaQJrBy+P+7TbbTdWFq//lAbmkxeMspuS6L3Ftx8SNhP4Gt+xGXi4fLswOh4SP6AaR+ym\niMI0URjwheN2vLCKzlKtUKSbFhWKkI1k+apsHtqgQamy1dh8axsLBoUNbrkuqLstR3vd++9DEdpx\nZF2hpBlbyyhh/fkC7xs83rr7n0ph22c7Ojpy3Vj8Akqb5gNrNpFIOHrb1dWVRqORGy840rakK8rW\nJoqRYeuPBR4UsQu42r5XJcnpj5OTE33/+9/Xq1evHNvD1iaKgigxjkql0kow1EJi6XTaebkE6sna\ntIlXh46nrZNPorRRMLZQSxwl6EeC7UQS9R+NRs7l24U7ve6+kj5y0+I8c5SSisKyCd5RQOeh5/YD\nOJbSlEwmV4J0UYKlTFLCeDxeiS1gIRKcu7i4cOm5KG3L4iFQd3x8rGKxqGq1GpmdaHnVu+J+PtSy\nL8Vt+dpR/28tx6jnxwrFQ1rHrnlq4d1oX/fq1SsHBySTSae4130Xi1S6T1cfDoe6uLhY+azPXkKI\nwQwGA11eXkaOBZ/3E1msgWaNiVwup7OzM/3Kr/yKy5XwA9tR90BpW0/Q99xTqZSDTWBvTSYTvX//\n3mVc27331PKkSttinpVKxZ1q+Xz+Izd6nfhRa8Ra2gQFthlQTt9er6dsNvsRO8EuhE2YFocSRdPv\n7u7U7XZXKF/rApBWYcf1OnDLqe+RzWZ1d3fnEgvWCZY20ffBYOCCiNbqsAcCBXgsHOUnPPjWqT9H\nBMFI7bbQih0bPybgb2b7jPsQ7hE1xta95n5+co10X1fDZ+BY7venELvvSP/mYOf/bbyCg5X5y+fz\nrrlItVp1c2eNAg5+DCab9MXa3lSLhXGkpCrBdJSo3fNY2tZj5/84WAm4jsdjZ61zABQKBTUaDeXz\neQcr2kPCV+K+F+YHp4mV/EJh2is3/G4Cksmk6+PHBl+nqKx7uS7wh9KwSjtu27EguM8U6/V67mT1\nS1JahsQ6waIpFAqq1+sOV+M+UYsWfA2lvW0tE7jX8/ncdfFgE60TAmccdIPBwFEK7bj4i9bn0fpK\nm+9FzSelUFut1konFv87vlu7iZa2L/EPB38M+Ax/9wsXEewlpZnxt2P2qZV2IvGhljhJI9bdRzjM\nLTxER5dqtbpSi8N+r9PpuM5EtqN5Op3W+fm5zs/PV/osWrGxIkoS28QrC0OgL6JqgrOmbQOH8Xjs\njJd1StsG05kvn7pp78vcszZsrslTKO4nt7R5KU7+bb6LBVsul1302WJVRMmBSQjUxbHKLB0Jip3f\nisl/hyixjAHSdYGA/Inl71CqtrGyo57dJur0+31n3UUpCz+os6nllrVSLB85ilZoLWF/nEhYiCrB\naSsQEiy0tV56vd5HhZfsc1nMWdJH9bOjUu55fgKtg8FgBeP1jQWUBMoED4egG/PHfIdhqHw+r2Kx\n6A7STZDVocTfd5JWKtT5SSfMpU1OwnNE/PlPpVIrvTcJ7lqv09bDt4KyhanhJ7P4BsA6w03SCuTH\ns1gdAPWQ4DCGGW3HoJpiyPT7fddtibgN784BJ+kjb+CQyvuz6FzDpjk6OnKn/Ww2U7vddoPHZ9gc\nw+FQhUIhNovEckkfQ82yiiQqw9L/LBasTendVkiKsc0Bbm9vY1l361g3vlhsEZjEblqf/rbuXhwQ\nfgajpZFh8bMBoZPRW9KOHxsQRQl+yjMnk0lXj8afT7vxBoOBWq2WK5Qfhvc1XKJKDUj3pWILhYLj\no3NfvKVSqaRGo7EStH3OYr1BH5cnDmVTwbGQB4OB2zsU3rLBOtbNuuCdLcfKuFtDJ474nh+ekL8e\n+Rx6BKMgmUzq9PRUxWJRzWZTFxcXLmDLugD64/D2a5usg3/2KZ+F0pbuN2ihUNB0Ol1RShZ/g9rU\n6/XcZ8FkN12bhWQLyGw7+FFYsLVk1lntvIcN7G1zYmM1sQiJ0KNcH1IU2waAYafYdGU/KLnuPix0\nH6O2VeJQCtC+NlnaKAmb7EKhKwtV4Qr77jSMBWoucw9rQdr1YA83sicpFUqhIavoCDDT5u25ivU+\n/PXK+1uPEIEZYg0EC6UlEgnnYSUSH0oARFnaWMZ4YKy5bSElOz/+GuP/MQZ4RnjfKHxqcF9eXqrf\n769AeYyD1T3WcIGauu9iX1Y+G6UtrSpDG9yxQT76wcF+oKbEp6LnMMmbCmRh6dnCUCj8OGLHZbm8\nL3wD/LQv6856Eda6llZxyW2xZ9/Ciotp2+eZTCa6vb11iVtYegTPyuXyR+PPNa2VTTU+Szfz1w2b\nkbXWarVcDQuKcFmF9xwYJJsk6rl8CG+dEE/BGgVDtodAt9t1cElUrMMe5hy621Bq/ee2XoI1irjX\neDxWp9NRtVp1NNtisagwDF3mJzEJvEK79uy6C4LAkQ1YB8lk0jXjOIR8Fkp7nQULjuYrjsFgoOVy\n6ZRgEAROgW1ahHFggl2e/SG+OPVAer2eSqWSw9LjcrV5H3BIDglS0vcpuMnWG7D4uF8wiGdcJz69\nyw90WismaiPzHZKKer2e2u227u7uHG+cFHjfe+G6tDGzStt6DuuCs9YqazabK0W++OznoLStbANF\nSPclBqhjTb10uy7Ift72HnGegXmyzC4Ly/hxHTyydrvt4kB4DhwavIfNgrRBaPa0vfZoNFK321W7\n3XZlXW2zX8ZjH+/+WShtJJG4b3hKKVUbFLMuy3Q6VavVkiTXVRr3GxfW0stwkQiS7WIx7ipY2kdH\nR26hbIJz1onF9Cgju08M1SohG5Dk3usgnk3CHETROKOUphU2IJs2CIKVBgmsg3a77WpV+Fa8DSha\n6p59vnVuLolQ2WxWk8lErVbLBdoo8rXL4e+7989NfLgh6jntv1kTUXGBXWSxuO/VSTlmWzaB8q+F\nQmGlWTbPRSEs6UNcwga+YXtRtsHSIq0QY6NeDz/9fn8FHsLj3ec8xlbawYfSrH9f0rswDP948ITd\n2BGsPMj+9XrdWUq2xgBBBvjA7XbbNXElRRyIBQEPfUqlzURCIcpkMiun+y7XQ9GBb+878IUSsz/W\nsraKO45lYbFy687a91k3DyhtrDv7DNJ9bRCs4XXie1c28Cittwyz2axqtZqk+6bDNqFrG3bUQ8/0\n3MRaruu8ID5n0873YWmyv9nbsHaI7SQSCdf6DAYJHidURxgmtgMVQWlbfG3duwdB4Fgx8NDpczmf\nz521bb38fck2lvaflvSPJZW++/ef0xN3Y8ctod6A3Zy2JKR0PwEsJv4+nU5dWqq1tC0jxV7LUr/2\nLSxoCq+TgRU3jX3dNde59r7YAKOvMKXVRWyvhZK13W74LG7i7e2ty/DEIreV31DEHMQWbsDL6Pf7\nur6+dhj1uvd9SLFtc/had9Za2FYp2SAjHXnAYcfjscv6y+VyWweVpXuLD67zcxTW12AwULPZVK/X\ni0zm2gQRQS6IekefjRRl3VPHCKNNWo0hrWNkcU3q7lilbQ96+5z23swln6duCpBsIpFwXZmgntok\noMdK3Ma+byT9MUn/saQ/892vP0k3diCSarXqEkkYmF6vt7K5bQCL6HSn04ksA4uCZhH4nSoOpbQJ\nHJbLZdXrdVcTYZegqbXOHqLfSdFwhxUWr9+TUbovR2AtLVxLioFJcnghUXW/6BOMBILI9LGUpF6v\n52hXT1Gn2IqP1/uWOBBIpVJx3eoHg4Fubm7UbredFW6z8fygWJQwd2Cqtl/hoWQXhgZro9fr6ebm\nRp1OZ61laj0Wu48gCxB34tooO7+Js72/hb+sscY42yzeqMAnOsHmYthg5bqD3tcZ7I3JZOJKGCyX\nS8fvluSqXu4rMBn3Kv+ppP9QUtn87sm7sduIPBxoamMwMVGtgTiFGdyoiDJilRATt4vCxiOwZUbX\nYX/29N6VbijdL6KoetO+YJH4nWKskMHY7XYdjW7ds9qNTIMGkqAkOe48BYWYE5JqwH8thcp2PX+q\n+AISFQxlPHHFSZxBsaZSKXW7XZeV2+12dXd3t4J9sg6i3sfCZcPhUP1+37WB25fs6+CzViaBO+s9\n4UHZNWUtWWq40N3I7kk8lm6364pawb23RpSf1GW9JIttw2iJ6qoTd13Z/WKhD7sHjo+PValUXFyJ\nZKrJZLJXiCROj8h/RdJVGIb/MAiCLzd89EnBNwaKsoqcYslk0lGPfCWJUrASlXXlK/NdFjrFkwhI\nQSWKciGtZcVndkm0gaOO27dJ8FgI4lAhzR4W8JCbzaYL1EUxKaTVIChWEtaxZcf0+/0VvjUWKX02\n7T3iQDxPIXaDM27FYtEFu4CAgiBQuVx2HU5ub29dqU/bF3FTSzzGi1rzYOb7eo+ov+96LRv0JjnG\nKjfGiLEhkYWfdDqtRqOhX/7lX3YeH0q40+no4uJi5QC3Ac2HPBZqCdlELvTCLkLWcblcdl4+RgiB\nx0qlokajIemDHhoOhy67c59B5TiW9h+R9MeDIPhjkrKSikEQ/A1Jl0HMbuw/+tGP3N+/9JpX7iL2\nRKVVEAqZRZNIJBwksonix8lv4Yh1ygnFjvW8SbFijcG7JkuMgIg9EIhww3elAllU6vW695DketVh\nnaxbJBabxtJmHO19OATA+DeNibWSSAm3QVUOJdxZhBRpW5fCx9WtdX9o8d8RWped+3K57Dqe0A4O\n3L5cLjsLq91uu6AYiozytpvEHnKUGvZpo7uOBevdh6nijEvUmuWA8mMUNI6u1+sOemNd8JNOp13b\nPkuhWyw+FNrC2xiNRiuHBLGtTfEMlLY1yvzaIZssbQuzUH+FlnR0rOp0Og5utZUB0QkUX4vrPe+t\nG3sYhn9B0l+QpCAIfl3SfxCG4b8VBMFfUcxu7FZp71tQ0rQAI6DXbrd1eXmpwWDgFoT9kVbrJ/jc\nXX7Hd6mVwmKglsI6nMoqbWtpS1qBX+yiA98Nw1AnJycrvQfXibUCYTCQ2UfarX8gsfDZtEA52+Do\ndjHaLEmw3evra1WrVceP9rnb/rXIdqUanJ/5+FjoKOrePgQirR4SjDv4aKlUUrlcVqVSUbVadXi2\n3eClUknz+dw1mkVRYDyk0+nIJhVWLDuCoC5W/WMSxMIwdIcnta/j0EL9wLadY3IiGE9w6mKxqEaj\nodevX7t5I7hKbaBEIqFqtboyp+w5P85ig+I2I3GdcHAQBCQrFbiv0+msKG8rzBPZtNaroskCuoBq\npbw33irNi7me5WyvE9+gfUw39nXyl7VFN/ZDCQsC95PBPTo6Ur/fXwke2Q4nkpyrJd0rBos32poL\nFiOjozQlZaOE05deelYpWmZLFCZH9li5XF7JplwnpKoTBERpo5ztpmDzWSsLpb1O/EAc44XCJkOS\ndwJKOTs7c41vfYvGvxaHHMwZG1jiHnzuMRb3usCyVUx4XjaLNZfL6fz83LXGK5VKK+3UJDnFLknd\nbtc1CeCAtJbbJrFMHHjIktzGxyKNeo9N7xyGoavlggW7Carxn8dW/6Oh9GAwWFH6rHkouefn524M\nSR8nuB2G4Qp8wvv4AXLrxdmSFf6PFfYfeR2VSsWVIQZ28fueIolEwq3FRqOhRqOx0qCEg5gqpYj9\n+6b99FjZSmmHYfh3Jf3d7/4euxv7UwgntE2+wSKCR0mGJFQ12kPRRiuq6BEbsVQqueQcMK1dcGe7\n+FAU1i2Ee8qJjfW5aaODY19dXX1EWWTx2zEikLtNlxzfI+F6KCU2F9aLdZ1xZe217N9tVuJsNlOp\nVFIQBCuVEpfLpcs23IYG5zMC7JjYgwxFgiWIOwzvl8L5BE1twwg7HrajPPXUr66u3CFAvXNb0Cjq\nmW2CmE2pt8X7t5EwvO8LCuwSxcyIEjrV8K75fN7lNOA9sgYo/HV6euqUmiUQcMjx/D4kFyVc2+5f\n231mk5fIPbkGayeXy610YfLvh6FmjUCelXXiF8N6KvmsMiI3iVXaWMwEDWq1mnNncW04aS8uLnR5\neflRPzp+MpmMzs7OdHp66hQ3E7itwkbYlNyDBQeGjFV2d3enWq2mer2+cVEAiaC0sX7CMHSwhXXh\n4RjbOifrntP+2OsgbAS/HgnBSLI7o1gz0r2Fa5sMc6CAd7OBwJJtwaK4480hTXq7tXjxUvBUut2u\nsxKJLdjSCetgGovncrhfXFzo6upKuVzONRKwyR7roAmCb9Sn5uBAoWyrJJgbIBc/r2GTjEYjXV9/\nCFlhrKC0bQASGmStVtPZ2dkKlY/xIf6ExFHYKHn2HbEBrN+ocq/2nnw/DEMXGD45OYmNaduqnxzu\n0+nUQSiSVoyAQ8tnpbRZeARB4LFaq5cJymazLsCBteorKbBTgoR+9bnl8kOVN/rPwQZ5bC0Ja/Gi\ntK3VR1o7ODVlI9cJCqff77tntgE07sG7cHgVCgWVy2UVCoWNz2vHw3dHgaS4F7Q/LEWb1pvP51Wr\n1VYodJVKxc0LliiWE5RBvs+G2zXFnwPFWtoc8BbK4nC2lrb9sa581NzaeST4RsYrnsPR0ZE6nc7K\nmot6ZizBTqfjarzTUNeHEVBovtcILDEej3Vzc6Nms+maDGwSC9tRNZLsUjBxAtTMna1Jvw7KirNv\n2MPl8geWMV4Xlrb9ifJ4193XHjB4PMSrrEfKnz68OJvNXDIRe4kD4anks1PaYH3NZlO3t7c6OTnR\nycmJ2/T2xD87O1tpr2QxMunD6dhoNFQulz/CbC1maE/bx56o1nLgnlGMCfjMKOxN97SbU7rH06zH\ngIVWrVb1gx/8wJUSBW9/SOxhZoUWViTH0N5J+rDA+/2+6wpULBad8uK5qLRGB3g2eyKRcCnCbJ51\nSUBxBMVi59UGIlESxWLRsResMojCTdfdB6seDBXlxuY/PT112ZIoz3WMEg4baomDw1Ij3AbICVRC\nw8MqhCNPhunNzU2sUgncG/YEbfio7Mdc2/Gjc89jS5NyyJMSDkRZKpVW+qDSVnCbPWlphOPx2I1f\nlDHgX3c6nerm5kY3NzfOcj8kfh0ln5XStpuBGsiFQuGjzEWrGDcJn9nW3d5GsBALhYKL3KOA2OBg\ndLaTiMU9tylVafFl6T5IWSgUVK1WdXJyokaj4RrvPlRn3AYCeTabJgx8I32AaaxSBafO5/MuDoDn\ng9K28QY/wceWlz20PIaVYYX1h5XYaDSc58GcYwjk83nV63XnKVlF6ntytvkuisziyHg8HALWjYet\nYTudb0P141nz+bzz/iwPHywf/JemFPtQ2kB58/ncrRM/oIkCj/s+MKioFUK3Gg6DqOeOosnaPfuU\n8tkpbWtFwFawNL7nJrbbDhvI76hBgA12im13hKXmZ3luEjYzf0+lUqrX63rz5o3rzBGH4meDN0dH\nR86VTCaTK4FeemGiSFA24/FYrVZLlUrFMXwoPSDdKwQ2y74U56cWW1ebBgkkFhGrmE6nbr6vr69X\n0vwZFwsvcGjTQQWlDo5OAN6WdiBOY63uOGwRXywd0zaJsPx5rOFyueyU9mM8UpT20dHRCqMnlUpp\nMBjo6urKJdCR9BJXgFi73a7ev3/voE+yHTfpkuPjY52dnTkjiOJzT6l/PiuljdgovXWnnyoQsI0Q\nMME6sFgjYlOiCZRSu4BkGRKFHqrBgZK2FkAikdDp6anOz88dfzQOLoyXUC6XHWaJJYKyBv+lMbB1\ni4FH2FwcFE9tmRxKfK699Uwo/AU01Gw2dXNz48ZiMpm4uAIQhsXdfYsPJWlTurmnpbdRB8VCZjZe\nY6G5h7w3romFe3R0tJJty2EL/c0G+uMosXVUUguFEW/ix/K1qX0eF7ry72HHm2uvGw+uT90jWDzQ\nMZ9SPqvdA3/SZqbZRfIclTaKT/rggler1Y+i1lhKtrkv3FJcW4r7gyNGWUt4HLZiIJYs7Bmw0DhC\nXCCfzzvLzfKWLSYOBFMqlVaqnlkmyWw2ezK44ymE92KzA1XYg4sgOdhzt9tVt9vVeDx2gcN8Pq83\nb96oUCi4OZbu4cBNGZQoHtYUlrpVypaPD+TEs29SVsxno9Fw1evwdFOplKM/ZrNZnZ6eqlarOU8x\njuA5287mftzJKmkOLOICklaooXGE2I4knZ6eun1XqVRiMcJg8ezC4NmXfFZKm00BfmYjwYdS2NYa\n8E/0OPe0FgNBriheqM9OwIrDomg2m8pkMq6SYRSGx1gUCgWdnJw4JW0X2TbBtEwmo3q97g6aqPey\nUXU2OV1K2HC2O/YhFrofQI5iuRxifcB7RlFiedpiQjZpCL7veDxWv993sEUul1Oj0VjpBI6isgX8\n7Tvad2at+Mrdxnd4FltECQrbuvVULBZ1fn7ulLbNasXDBdZrNBoucBzXgLJwJ88p6SMPg4AjUCHQ\nBHCczUXYdC/GjLXLMzM2cWDW5wDjfVZKW1qtB8G/DymLxcIlimAJ74Kh+9QhaZWh4v/wWSCFarWq\nVCq1Ujhn3T3gOdtek9t4IjZjzSof+86+W4rnc3p6qk6noyAIXECM7DkCkYdwKbHYCLhxeHHPQ2w0\nKrmBE1PDJUqwcovFok5PT91ctlotFzNoNBoOLuGgo/ciSoe5sRmKUffifpaRk06nValUVKlUXFBy\nU9ONer3uyjXg4Upyxoc9JHbtRI4nZo0We7Bb7jt/Yh1jhMSBR0jgol67zbBdx7t/rvLZKW0pPv1q\nH7JcLlf6N/rpzXHFBgfjft4qTJRi3EDkY6xMeOJY2zapY52gEGazmb799ltJ9zVW+v2+bm5uXKbq\nIYSYQbvd1vX1tdLptM7Pz93YHVJpg0dL65NlbABX+jBe3377rdrttksYQjFhKNhkHxuIpEM48JMv\nwIck+NDhnoOh0Wi4RrQk2URBMAQWwW+BcrDqWSfD4dBBQttS7zjYbXahFQwX1l6UxxtHbAIV0N5D\nRd+eq3xypW3TjKMsTyv7UtSW72opcesK8qCod7Ek9vHMT20BWEqiTSTa9Bx8x9YQt0EwrEcCYvs+\neC2TAivssUlQD4lNpSbQug7P5RmIVywWC7VaLaVSKfX7fX3zzTcrSVyUT+Dz7A88CXj8UY2bbbEj\nauSgEFHgYMBwoaM8N/BqG+zHy7Wskfl8vpXStrEOaLBAQ1GlAeyfuwoHIQwe9vNju8kAx9lSCMSV\n0un0SjXF5XLp1udjjIhPrrSljwvNHzolFLpPt9t1yvuLL76I7BhjFYFdmJ+LK7WLoHyhnsXZjNYr\nYLzsgsYy89kv+xpHm2jC4Utg6VBzhXJF4cXNDTg+PnZUtePjYxdkrtVqOj8/V71ed63aKKzPHvFL\n3EZZyEBi1Eq3VEyUIgHvh1K518WM/ENym7IOrAe8FDKbeaZDWL4wdvr9vtLptJu7fWQy2izmXq+3\nkogHzZe1Dzngs1bauEcWoyO4sYvYmhZYegygxa5s0ghUKJ6H4jx8FrrbLi7gvsUWm7KBlcdWv7OC\ne20tbX8j2QxJNj6BYtxyqsnZTixYiZus0l2fmUQpAtRYNIeaL79QkF17eBh+kJkf8O16va5Wq6Ve\nr6dMJuMCbYVCwaVpW2+UxA72yqaAtFVOvvg4/7p1ZamHNsOWeedwYJztNdbFEnzozwbK+XzUvR5a\n53Yt2pIFtjiVzdjc59qwOsUadlHz7z+zHX8alG9S6p9cadOlg828WCwii81sIyjs0Wj0UZoqG40E\nEwuPQGmCVsSmt5mKz0Fp2ySJMAxdkGhfuK3dGOugKr9SId+jQ/XZ2ZlLx59Op+p0Ojo+Ptbp6amz\nJPettKEiwt5gzp56vrCIbVcTDik2bTKZdAkhpKnz93VJVEBQrOWosgJ8Li6rArHuPYrP5yFDh0J3\nDAAAFfpJREFUQSRwaHFo7gnTY7lcroUBmBuC+tzHzpNlTrHO7OGwTlB8WPE2v4CKn34g87HCwWBr\nILEGmXMLj/hjwl6C3ov3sk7iNvb9uaSupKWkuzAM/3AQBFVJf1PSL0n6uaQ/EYZhN+6LsjiHw6Ha\n7ba63a4r81itVuNe5iNhIZOmSho1tRNYbFAHrcWQSCRcQRxJLiX3oUF8SmFTWL4277MvicOOsRxb\nPBUOx3K5rJOTE5cmbLnmBNbIskMes3nsocIh+ymF3pq3t7dOYUOHtJYXrjLwSCqVWmnVFoX9H4oJ\ngzFALXQ7p9b65fmw3vEG+H/bfmzdc1pohbXrG0Mobdtk+yHmkV/mgro3yeR9WVdq2ewL5rTX4jDl\ncLXYuZ+AZZ/ZKu1er/fgXo5raS8lfRmGYdv87s9J+jthGP6VIAj+rKQ/ry26sdOZ4/b2Vu/fv3du\nIdl3jxEUSrfb1eXlpesVh3tprWafOjgYDPT+/XstFgtVq1UXHHqoEt5TCYvZpsNns9m9YHPbPofN\nuGMTQsuq1WpqtVqufjQw2HA4VLfbVT6fd9/73KL3mwTFcX19rT/4gz9wY3J6eqrvfe97riqctVAr\nlYrOz89dcLHb7TrWxlPxgnlujIHFYuHiEv5n/Bra9v9Zn7PZbKOCtYcsgU0r9oAgCYiA7KZ3YPwo\nV0z51qjqnPuwsn1l7F/bKumo9+T3UBKp1LlJB8ZV2oEkf2f9lqRf/+7vf13SV9pSaUNpur291Ww2\nc9Xe/AazyEPp2/ZzWPGtVsthnASANp2wlK+0XToIbj0HsQkJlp3xKZ7Dpkqz+XB3baovioC09k6n\no0ql4vDYqLnYF6RhcXd+/INin/AJ89Nut/X27VuHLUty7jnuNMqbFmXX19e6urpagZUeyzTY9rlJ\ntolqEMCcM99RMI4NOq+jP8ZRmtyLQ8I+z7ocDXjsBATZ++sOmX1IFNNl02eihHfCS0ilUhv3dFyl\nHUr6v4IgWEj6r8Iw/G8knYVhePXdTS+DIDiNeS1J925suVzW69evFYYf+iJWq9UH3YMoeiDCyXZ0\ndKTT01MFQeAwsyh2iC+0lZrP5y6p4DnVyoAKZsubgsc/pdiUbVxpXENqPTN+1IG2sEGtVnOYo6WT\n7fs9FouFa05MwgqB0rg1MrYRcMzT01P98Ic/dGuT8sHrMNkg+NCOi9gObny9Xt9rR/Z1QjISgXkq\nMNr9Asxgg4Z+Igz8cNgguwrxEWp4z+dzF2ReZ7Gy9mjTR5ErPJbn6NFZqixFxij+tU7iaqM/Eobh\nRRAEJ5L+dhAE/58+KHIrW/nnVmmDaVGQf9PgWmogVpOviFEo9PNDscdJssjn///2ri02suyqrm23\n249y2eVntU13uidEA8NIMMzHABOhnmFCZgBpwldIQIiQXwQRIEQSPgKfICEUCfKBgFEUhUSQENJI\nkdIajdwaPtAkGobJm6E7dBu7XVWu99t2efNRd50+dbvKrirXrbrlPktqtX2r7Nq+99x999l77bUj\n2NjYMNHEKKQXTwKLqIz8eQ6GXWxjpNiOvmdLhbIpg+kc6oNvbGwYidDj42NDFex0Q/aLRqOBYrFo\nBu3m83lsbm6aB86g6ZvMY1LXgrsRii61u1a0gSwbTvvh7nAYTrubdUWn7bfd/pr0v7NeRzrt2dlZ\nE2VzN8c6jh88XyLNsWxMM3Q7Um9UYAqM+kCnrcmu/hJVve/9nxKRfwXwDICEiMRVNSEilwAkO/38\nn1rT2J/zJg6T6mMXIlg0ANpvKbjFtv+RHsWLwp/jU99+AHTztGXRiGkUe3sbBpzVydjFQ95YdjGp\nFzvs/9u9xrTS7OwsSqWSYR6Uy2Xcv3/fPEQnJycRi8VMG7efSncW2FxxFj/bzXccJJgiEnmgIUPG\nQrs1SLvW19eNngmLkizGBc2E6WZddbv2BkmjOz4+Nl2XfLBz59xujZBdw2CiE888LLDtev3117G1\ntXX6z5xWwBKROQATqloSkQiAmwD+DMALADKq+udeIXJJVR/KaYuItvsMvwIZ8DBrwX+imRPlRSyX\ny4jH47h06dJDjAE7h2n/vtMWnr812K72nwewmYGO266sDxq3b9/G7du3ce/ePezs7KBQKJg0Ckc1\nAc1rdeXKFTz++OOIx+NdT9PpBrVaDalUCplMxlx7zg1lVDbI/Dnh5zzbPQL2Z9osHHtQQTabxdHR\nETY3N3Hp0iXDzDkv6/A08N6tVqvY29tDKpUyOzjquPsZXf3e82GFiEBVHzK8m3AmDuArIqLe+z+v\nqjdF5JsA/klEPgrgLoAP9mKQzVftFaxQc5Hn8/kWYRyg/4j0PDnodrCFczhWKyiKHIe85vN57O/v\nG7YOH74U75mamjIMgUGzYLiDY16TfNqzti+3g/37etkp2A1MfGBRs6VcLmN3dxdLS0sm5znqXoFh\ngjtBe1LMSXWBbop+pCRy7Z3lfvdz120edlDX6NSVpao/BPBUm+MZAO8LwqhOEHkg8M/8Vrlchmpz\nQOzy8nKoc1dhgD3ktdFotOhQDBqcep3P53H//n3k83nDeKGcqV9kf9Bpi8nJSUSj0RbN9bO2EQ8a\n/HtZkKWwVqPRQC6Xw/b2Nq5du2Z2BkE8cMII1qGWl5dNUZRpz36vH5k5hULBcOfPGqRR04RFWD8X\ne9AYKw/HBctctWpT9YyKdMxX8r2jhN16TLQrQPX7e20+rN2Sb+dMO0UjjOqCLmKy0YZ890Kh0DLI\nlukD/2itQYI58yDngJ4F/tqArZ9Sr9ext7eHRCKBWCyG9fX1E+cYnifYDzLWrQYBm4/u56H3i1qt\nhlwuZxgzQRTUbYyV07YFaiYmJgwXm+3C8Xh81CYa2DoIXBinOdRuwe61RCKBVCplCjOcVn1S9yYd\naSQSaeFVBwGyb6ghXa/XkUwmDW+WhWXKDbAT8FHfLfG8MVVy4cIF0zHHFIFDf7DTLYPasdTrdSND\ncNo4wEFgrO4ORojspGs0GkZgPxKJGGcQBvibT2yWhldg6DvSZpSdSqVw+/Zto3tMIX7qHrTDoCec\nd1qgjOg5I5NOu1KpoFgstsz7Y5t7tVo13O1ODRSPApgCsHO4lGWg7vajfH7OAqbHbAG4s+Lw8BCV\nSsUMIfYXQ0+CvSPv9lqOldO24edrhw10RmS5iAiWl5exuLg48GLnwcEBCoUC5ubmUKvVWvSkg4ad\n6vCPbKLjnpubw/r6uml0sc8LO2NTqRSmp6dxcHCAjY0NrK6uGorXowb7gc81XiwWzXHuREY5p3Bc\nwTz5IGsDi4uLuHz5smmX7yXlyMIoNcm7sWlsr7jNvw2j42Y7bTabRTqdNlEnc3ODdNpU/YtGoybF\nMEjVv5PAVE2j0WiZMMIKv4gYOUwRMQ0udODUGaZ0wOHhoZEt5Y31qKGd0y4UCsjn86bTlHUd57R7\nB9fpoHYpCwsLxlm3U/E7CbYwVjt9lHYYyytut6uqqpG5DNMNTuEkFtrovM4aZTN6vXjxItbW1loe\nVrFYrEUeclBgGsOeis2CcLlcRjqdRqPRwPLysplqbdOy6FxmZ2dNEw1F4+mcmBdMJpNGAGttbQ1r\na2uhb5AYNBgNsjt3amoK5XIZpVIJAJDL5VomvDt0j5OawvqFHaD0et8dHR0hl8shm81idXXV7ALO\nndNm8SwWi7WoyoWpQEPHRdt4bBAsCWqrxOPxFhlbbq8GzcRgNM1ZmYVCwWg65HI53L171xRgGC20\ns/nixYuIxWJGtjWdThu+uF9giBO6qbPyKHGT6QTIellfX0cymUQymTTqlRMTE4hGo6M21QEPD7nu\nBXTau7u7mJqawtLS0qmR+lg77aWlJcNp5ZYxLDd2UJKaNjXM38loFzXsNnV7QfVzfui0S6USMpkM\nUqkUVlZWWsSi/HTDdjZT7IqMkUqlYtIlTJNUKhWjzsaiaiQSMeqPtupdkNfaPpe2zo39mUG2lHP9\nUDyIBa5isWimAVWrVVSrVfPece7+CxN66azs9b5inwLFyygQ1ss9OpZOW0SM9gDzftyuP+qgw7YH\nJJzVydkdqNlsFolEAlNTU1hdXTWqiCJNXWi7K9UPcm5FxAyk3d3dNVrnbOculUrG9mq1ipWVFays\nrJiuQGrVBA07twxgIOeyH9ipNarwiUiLaD51e8LUNDTOsOtlwOA0TMg0yeVySKVSKJVKpoGIKqTn\n0mlzq92Nk7b50oOIOsMMmw5YqVSMnCUFkk66of3NQPZiBVpHWNnNPJzWPTk5iUgkcmIhhpNHqBdM\nTWZGiyxMcgQdACOrytc4usmO7P02DgJ88DEa4rgr8nuHTUvk5zKVZHe1zs/Po9FomGt93tb1sGFr\nW9N/kDffb7DAtUIJh0wmg3Q6jXq9jng83tL1eS6ddq9gAa1d1+B5AguGxWIRyWTSRKkURzotL8zI\nwj+Nxo6Qp6ensbKyglgsZoqOtp72aYuOW39qgXDWZTqdRjabRbFYNIJWdErU4eZUa/49th7FoCmO\nbPdPJpPY3t5GrVbD2toaVldXsbi4iMXFxaFH23wwAs1iJG/8+fl5MyTYFSbPDuq+ZLNZE3FHo1Gs\nrq72RXawA6FqtYpMJoNyuWwUC5eXl3vaQT4yTptdk7aC3HnbStoDjff391EqlVrE5E+7oemwyRCx\nh5RGIhGjsEauMF/vNsK18/HUG+HDwdYdoTwB7WCem2mUarVqtJ8pdG8Pzh1ExM1uzUwmgzt37qBY\nLJrB00xXDOvhb/893NkcHh5id3cX6XQatVoN9Xp9aNrb5x3Hx8eoVqvIZrMmPcb0X79gxE4qcL1e\nN13M7XS0T6IwPxJOu1gsYm9vzxQwo9EoFhYWAhNKGhXswRJXr15FvV43f2c3RVpuu1nsYlqFP2uz\nGpgq6dc58ufIW7clN3d3d5FKpUyhjbll8pSz2azpDIzFYmZ4Bh34/Pz8memf3DlwmANvYjYSUWiL\nD8Rhged9enrajCljgdZxtgcDjoATEbP7nJubO1PNjOt9YWEBV65cMSqD09PTZkoR31Or1VCpVDr+\nrqFc5a2tLTz33HPD+Ki2KBQK2NnZMY0JBwcH5mR1wqht7hVbW1u4fv26SRUsLCwY9kg3zpVRdrVa\nNVKqVEFjaqQTD7VXx81o+tatW7h+/ToikQhisRhqtZqJODgjj3nF4+NjFAoFlEolE+HOzMxgdXXV\npICWlpawvr5u8r9nAYdfzMzMIBKJmEGxb7zxBl588UXD2glKt6UTeB3YgMRr3El0a9zWMTB6mzlF\ny6ZUnsbB7sZmUljn5+cfYnbZ161WqyGbzXb8PWPptFm8qlarprvJ3q77wbwRCwr+iTbDsDlo2Pb2\nm/axi7Z2N14QuVsRwa1bt/D8888DgLkmsVgMm5ubmJycRCaTweLiYksXJf+xIJnNZs00nHw+j0Kh\ngFwu1zLgwH/DMQd8Ev+bTI1oNIqNjQ2oKhKJBO7evdsy13LY8NMnJyYmjD56rVYzbBL2CWxtbeHZ\nZ581Coudpr/w2rN+UCgUTPFtenp6qCO7Rn3v9dMoY9vMFEitVjOvcxfYTUqNqoGdMJb7KRYKWISh\nJGunbsP5+XnE43GTmwrbsF6HBw0l3JZGo1FkMhlkMhncu3cPlUqlhYLFomuhUDB875mZGezv7yOR\nSJi2eZtDDjRvyI2NjZbItJPTpj0ADNVueno6MO3vXkCnfeHCBaTTacOw4Zbepv8dHBwgmUxib2/P\nDLheWVlpmX/KFBTfu729jWg0agrO/iG+Dp1Rr9dNYZ2TuTY3Nzs2nrX7+ZFH2oOGvZXnFta+of1g\nZMGuvVFFSQ6dwVw5O1yBB/MsO43ZsqeGHB0dmcEK3FHxIW7PnGRBiWvhJJVCETH22IFBGBhILBDb\nuw4Wkf3yoMfHxyYKpxNZWFhoGfUHPHDcTJExBXV4ePjQex06g1TRcrls/FK9Xu9aH4kPz044dUbk\nWSHNMWUODg4ODj2i3YzIwJ22g4ODg8Pg4HIEDg4ODmME57QdHBwcxgiBO20ReUlEvi8i/y0ifxz0\n5/UKEbksIq+JyHdE5Fsi8nve8SURuSkiPxCRr4vI4qhttSEiEyLypojc8L4Pu72LIvLPIvI971z/\nzBjY/Psi8m0ReVtEPi8iF8Nms4j8vYgkRORt61hHG0XkEyLyjncd3h8Se//Cs+ctEfmyiCyExd5O\nNluv/aGIHIvIsnUsUJsDddoiMgHgrwG8COBJAB8WkR8P8jP7wBGAP1DVJwH8HIDf8Wz8OIBXVfXH\nALwG4BMjtLEdPgbgu9b3Ybf30wC+pqpPAPgpAN9HiG0WkU0AvwvgaVX9STSZVh9G+Gx+Bc37y0Zb\nG0XkJwB8EMATAH4JwGdk+JzFdvbeBPCkqj4F4B2Ey16gvc0QkcsAfhHAXevYEwjY5qAj7WcAvKOq\nd1X1EMAXAXwg4M/sCaq6p6pveV+XAHwPwGU07fys97bPAvjV0Vj4MLzF8ssA/s46HGZ7FwD8vKq+\nAgCqeqSqeYTYZg+TACIicgHALIAdhMxmVf13AH5SbycbXwbwRe/8/y+aDvKZYdhJtLNXVV9VVXIK\n/wPN+w8Igb2efe3OMQD8FYA/8h37AAK2OWin/SMAtq3v/887FkqIyDUAT6G5cOKqmgCajh3A+ugs\newhcLDb1J8z2PgZgX0Re8VI6fysicwixzaq6C+AvAdxD01nnVfVVhNhmC+sdbPTfjzsI3/34UQBf\n874Orb0i8jKAbVX9lu+lwG12hUgPIjIP4EsAPuZF3H4uZCi4kSLyKwAS3u7gpG1XKOz1cAHA0wD+\nRlWfBlBGcwsfynMMACISQzNqugpgE82I+zcQYptPwDjYCBH5EwCHqvqFUdtyEkRkFsAnAXxqFJ8f\ntNPeAfAu6/vL3rFQwdv+fgnA51T1q97hhIjEvdcvAUiOyj4f3gvgZRG5A+ALAH5BRD4HYC+k9gLN\nHda2qn7T+/7LaDrxsJ5jAHgfgDuqmlHVBoCvAHgW4baZ6GTjDoAr1vtCcz+KyEfQTPn9unU4rPb+\nKIBrAP5LRH6Ipl1visg6huDzgnba3wDwHhG5KiIXAXwIwI2AP7Mf/AOA76rqp61jNwB8xPv6twB8\n1f9Do4CqflJV36Wq70bzfL6mqr8J4N8QQnsBwNuqb4vI496hFwB8ByE9xx7uAfhZEZnxCkkvoFn4\nDaPNgtZdVycbbwD4kMeCeQzAewC8MSwjLbTYKyIvoZnue1lV69b7wmIvYNmsqt9W1Uuq+m5VfQzN\noOSnVTXp2fxrgdpsD7EM4h+AlwD8AM2E/MeD/rw+7HsvgAaAtwD8J4A3PZuXAbzq2X4TQGzUtrax\n/TqAG97XobYXTcbIN7zz/C8AFsfA5k+hWZh+G82C3lTYbAbwjwB2AdTRfND8NoClTjaiycz4H+/v\nen9I7H0HTQbGm96/z4TF3k42+16/A2B5WDa7NnYHBweHMYIrRDo4ODiMEZzTdnBwcBgjOKft4ODg\nMEZwTtvBwcFhjOCctoODg8MYwTltBwcHhzGCc9oODg4OYwTntB0cHBzGCP8PTDWPAhG1RVYAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e2c29438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected = np.random.randint(0, len(train_X))\n",
    "print(array_to_string(train_Y[selected]))\n",
    "plt.imshow(train_X[selected])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                               shear_range=0.05,\n",
    "                               channel_shift_range=0.2,\n",
    "                               width_shift_range=0.05,\n",
    "                               height_shift_range=0.05,\n",
    "                               fill_mode='reflect'\n",
    "                              )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_generator = train_datagen.flow(train_X, train_Y, batch_size=batch_size, shuffle=True)\n",
    "# val_generator = val_datagen.flow(val_X, val_Y, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mixed_block(x, num_filt, block_num):\n",
    "    branch1x1 = Conv2D(num_filt, (1,1), activation='relu', padding='same', name='block%d_1x1_c1'%block_num)(x)\n",
    "    branch1x1 = BatchNormalization(name='block%d_1x1_bn1'%block_num)(branch1x1)\n",
    "    \n",
    "    branch3x3 = Conv2D(int(num_filt*0.75), (1,1), activation='relu', padding='same', name='block%d_3x3_c1'%block_num)(x)\n",
    "    branch3x3 = BatchNormalization( name='block%d_3x3_bn1'%block_num)(branch3x3)\n",
    "    branch3x3 = Conv2D(num_filt, (3,3), activation='relu', padding='same', name='block%d_3x3_c2'%block_num)(branch3x3)\n",
    "    branch3x3 = BatchNormalization( name='block%d_3x3_bn2'%block_num)(branch3x3)\n",
    "    \n",
    "    branch5x5 = Conv2D(int(num_filt*0.75), (1,1), activation='relu', padding='same', name='block%d_5x5_c1'%block_num)(x)\n",
    "    branch5x5 = BatchNormalization(name='block%d_5x5_bn1'%block_num)(branch5x5)\n",
    "    branch5x5 = Conv2D(num_filt, (3,3), activation='relu', padding='same', name='block%d_5x5_c2'%block_num)(branch5x5)\n",
    "    branch5x5 = Conv2D(num_filt, (3,3), activation='relu', padding='same', name='block%d_5x5_c3'%block_num)(branch5x5)\n",
    "    branch5x5 = BatchNormalization(name='block%d_5x5_bn2'%block_num)(branch5x5)    \n",
    "    \n",
    "    #branch5x5 = Conv2D(num_filt, (5,5), activation='relu', padding='same', name='block%d_5x5_c2'%block_num)(branch5x5)\n",
    "    #branch5x5 = BatchNormalization(name='block%d_5x5_bn2'%block_num)(branch5x5)\n",
    "    \n",
    "    branch_pool = AveragePooling2D((3,3), strides=(1,1), padding='same', name='block%d_pool_pool1'%block_num)(x)\n",
    "    branch_pool = Conv2D(int(num_filt//2), (1,1), activation='relu', name='block%d_pool_c1'%block_num)(branch_pool)\n",
    "    \n",
    "    out = Concatenate(name='mixed_%d'%block_num, axis=3)([branch1x1, branch3x3, branch5x5, branch_pool])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 60, 150, 3)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1_c1 (Conv2D)                (None, 58, 148, 32)   896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1_bn1 (BatchNormalization)   (None, 58, 148, 32)   128         conv1_c1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1_c2 (Conv2D)                (None, 58, 148, 64)   18496       conv1_bn1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1_bn2 (BatchNormalization)   (None, 58, 148, 64)   256         conv1_c2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1_pool1 (MaxPooling2D)       (None, 28, 73, 64)    0           conv1_bn2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2_c1 (Conv2D)                (None, 26, 71, 128)   73856       conv1_pool1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2_bn1 (BatchNormalization)   (None, 26, 71, 128)   512         conv2_c1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2_c2 (Conv2D)                (None, 24, 69, 192)   221376      conv2_bn1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2_bn2 (BatchNormalization)   (None, 24, 69, 192)   768         conv2_c2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2_pool1 (MaxPooling2D)       (None, 11, 34, 192)   0           conv2_bn2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 11, 34, 192)   0           conv2_pool1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_c1 (Conv2D)           (None, 11, 34, 48)    9264        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_c1 (Conv2D)           (None, 11, 34, 48)    9264        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_bn1 (BatchNormalizati (None, 11, 34, 48)    192         block0_5x5_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_bn1 (BatchNormalizati (None, 11, 34, 48)    192         block0_3x3_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_c2 (Conv2D)           (None, 11, 34, 64)    27712       block0_5x5_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block0_1x1_c1 (Conv2D)           (None, 11, 34, 64)    12352       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_c2 (Conv2D)           (None, 11, 34, 64)    27712       block0_3x3_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_c3 (Conv2D)           (None, 11, 34, 64)    36928       block0_5x5_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_pool_pool1 (AveragePoolin (None, 11, 34, 192)   0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block0_1x1_bn1 (BatchNormalizati (None, 11, 34, 64)    256         block0_1x1_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_3x3_bn2 (BatchNormalizati (None, 11, 34, 64)    256         block0_3x3_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_5x5_bn2 (BatchNormalizati (None, 11, 34, 64)    256         block0_5x5_c3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block0_pool_c1 (Conv2D)          (None, 11, 34, 32)    6176        block0_pool_pool1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed_0 (Concatenate)            (None, 11, 34, 224)   0           block0_1x1_bn1[0][0]             \n",
      "                                                                   block0_3x3_bn2[0][0]             \n",
      "                                                                   block0_5x5_bn2[0][0]             \n",
      "                                                                   block0_pool_c1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_c1 (Conv2D)           (None, 11, 34, 72)    16200       mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_c1 (Conv2D)           (None, 11, 34, 72)    16200       mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_bn1 (BatchNormalizati (None, 11, 34, 72)    288         block1_5x5_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_bn1 (BatchNormalizati (None, 11, 34, 72)    288         block1_3x3_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_c2 (Conv2D)           (None, 11, 34, 96)    62304       block1_5x5_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block1_1x1_c1 (Conv2D)           (None, 11, 34, 96)    21600       mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_c2 (Conv2D)           (None, 11, 34, 96)    62304       block1_3x3_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_c3 (Conv2D)           (None, 11, 34, 96)    83040       block1_5x5_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool_pool1 (AveragePoolin (None, 11, 34, 224)   0           mixed_0[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_1x1_bn1 (BatchNormalizati (None, 11, 34, 96)    384         block1_1x1_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_3x3_bn2 (BatchNormalizati (None, 11, 34, 96)    384         block1_3x3_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_5x5_bn2 (BatchNormalizati (None, 11, 34, 96)    384         block1_5x5_c3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool_c1 (Conv2D)          (None, 11, 34, 48)    10800       block1_pool_pool1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed_1 (Concatenate)            (None, 11, 34, 336)   0           block1_1x1_bn1[0][0]             \n",
      "                                                                   block1_3x3_bn2[0][0]             \n",
      "                                                                   block1_5x5_bn2[0][0]             \n",
      "                                                                   block1_pool_c1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_pool1 (MaxPooling2D)       (None, 5, 16, 336)    0           mixed_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 5, 16, 336)    0           conv3_pool1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_c1 (Conv2D)           (None, 5, 16, 93)     31341       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_c1 (Conv2D)           (None, 5, 16, 93)     31341       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_bn1 (BatchNormalizati (None, 5, 16, 93)     372         block2_5x5_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_bn1 (BatchNormalizati (None, 5, 16, 93)     372         block2_3x3_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_c2 (Conv2D)           (None, 5, 16, 124)    103912      block2_5x5_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block2_1x1_c1 (Conv2D)           (None, 5, 16, 124)    41788       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_c2 (Conv2D)           (None, 5, 16, 124)    103912      block2_3x3_bn1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_c3 (Conv2D)           (None, 5, 16, 124)    138508      block2_5x5_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool_pool1 (AveragePoolin (None, 5, 16, 336)    0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "block2_1x1_bn1 (BatchNormalizati (None, 5, 16, 124)    496         block2_1x1_c1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_3x3_bn2 (BatchNormalizati (None, 5, 16, 124)    496         block2_3x3_c2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_5x5_bn2 (BatchNormalizati (None, 5, 16, 124)    496         block2_5x5_c3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool_c1 (Conv2D)          (None, 5, 16, 62)     20894       block2_pool_pool1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed_2 (Concatenate)            (None, 5, 16, 434)    0           block2_1x1_bn1[0][0]             \n",
      "                                                                   block2_3x3_bn2[0][0]             \n",
      "                                                                   block2_5x5_bn2[0][0]             \n",
      "                                                                   block2_pool_c1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 5, 16, 434)    0           mixed_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 434)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           55680       global_average_pooling2d_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 128)           512         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 128)           0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "output0 (Dense)                  (None, 63)            8127        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output1 (Dense)                  (None, 63)            8127        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output2 (Dense)                  (None, 63)            8127        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output3 (Dense)                  (None, 63)            8127        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output4 (Dense)                  (None, 63)            8127        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output5 (Dense)                  (None, 63)            8127        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "output6 (Dense)                  (None, 63)            8127        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,308,033\n",
      "Trainable params: 1,304,389\n",
      "Non-trainable params: 3,644\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(height, width, 3))\n",
    "x = Conv2D(32, (3,3), activation='relu', name='conv1_c1')(inputs)\n",
    "x = BatchNormalization(name='conv1_bn1')(x)\n",
    "x = Conv2D(64, (3,3), activation='relu', padding='same', name='conv1_c2')(x)\n",
    "x = BatchNormalization(name='conv1_bn2')(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv1_pool1')(x)\n",
    "\n",
    "x = Conv2D(128, (3,3), activation='relu', name='conv2_c1')(x)\n",
    "x = BatchNormalization(name='conv2_bn1')(x)\n",
    "x = Conv2D(192, (3,3), activation='relu', name='conv2_c2')(x)\n",
    "x = BatchNormalization(name='conv2_bn2')(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv2_pool1')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "#x = Conv2D(256, (3,3), activation='relu', name='conv3_c1')(x)\n",
    "x = mixed_block(x, 64, 0)\n",
    "#x = BatchNormalization(name='conv3_bn1')(x)\n",
    "x = mixed_block(x, 96, 1)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv3_pool1')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = mixed_block(x, 124, 2)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "loss_list = []\n",
    "output_names = ['output' + str(i) for i in range(CAPTCHA_LEN)]\n",
    "for output in output_names:\n",
    "    dense_output = Dense(num_classes, activation='softmax', name=output)(x)\n",
    "    loss_list.append(dense_output)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=loss_list)\n",
    "\n",
    "opt = keras.optimizers.adam(decay=1e-6)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=\"sparse_categorical_crossentropy\",)\n",
    "#               loss_weights={\n",
    "#                  'output0': 0.025,\n",
    "#                  'output1': 0.025,\n",
    "#                  'output2': 0.2,\n",
    "#                  'output3': 0.5,\n",
    "#                  'output4': 0.2,\n",
    "#                  'output5': 0.025,\n",
    "#                  'output6': 0.025\n",
    "#               }),\n",
    "              #metric={output:['accuracy'] for output in output_names})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createGenerator(X, Y, datagen, batch_size=32, shuffle=True):\n",
    "    batches = datagen.flow(X, Y, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    while True:\n",
    "        x, y = batches.next()\n",
    "        yield x, {name:y[:,idx] for idx, name in enumerate(output_names)}\n",
    "        \n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct = y_true == y_pred\n",
    "    correct = np.min(correct, axis=1)\n",
    "    return np.sum(correct) / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 890s - loss: 22.9756 - output0_loss: 2.8527 - output1_loss: 3.2406 - output2_loss: 3.5289 - output3_loss: 3.5254 - output4_loss: 3.5374 - output5_loss: 3.2467 - output6_loss: 3.0439   \n",
      "Validation Acc: 0.0002\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 851s - loss: 15.6898 - output0_loss: 1.5412 - output1_loss: 1.8215 - output2_loss: 2.9618 - output3_loss: 2.9112 - output4_loss: 2.9799 - output5_loss: 1.8106 - output6_loss: 1.6636   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 837s - loss: 14.4189 - output0_loss: 1.3759 - output1_loss: 1.5681 - output2_loss: 2.8504 - output3_loss: 2.7826 - output4_loss: 2.8534 - output5_loss: 1.5285 - output6_loss: 1.4600   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 3\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 796s - loss: 13.8406 - output0_loss: 1.2865 - output1_loss: 1.4706 - output2_loss: 2.7994 - output3_loss: 2.7128 - output4_loss: 2.7975 - output5_loss: 1.4190 - output6_loss: 1.3548   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 4\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 805s - loss: 13.4103 - output0_loss: 1.2277 - output1_loss: 1.4025 - output2_loss: 2.7362 - output3_loss: 2.6764 - output4_loss: 2.7342 - output5_loss: 1.3478 - output6_loss: 1.2856   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 5\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 796s - loss: 12.9320 - output0_loss: 1.1936 - output1_loss: 1.3517 - output2_loss: 2.5834 - output3_loss: 2.6728 - output4_loss: 2.5579 - output5_loss: 1.3189 - output6_loss: 1.2538   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 6\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 794s - loss: 12.5222 - output0_loss: 1.1697 - output1_loss: 1.3098 - output2_loss: 2.4563 - output3_loss: 2.7071 - output4_loss: 2.3542 - output5_loss: 1.2858 - output6_loss: 1.2393   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 7\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 794s - loss: 12.1224 - output0_loss: 1.1414 - output1_loss: 1.2703 - output2_loss: 2.3039 - output3_loss: 2.7157 - output4_loss: 2.2207 - output5_loss: 1.2537 - output6_loss: 1.2167   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 8\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 794s - loss: 11.7614 - output0_loss: 1.1239 - output1_loss: 1.2351 - output2_loss: 2.1936 - output3_loss: 2.6428 - output4_loss: 2.1303 - output5_loss: 1.2327 - output6_loss: 1.2028   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 9\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 794s - loss: 11.4064 - output0_loss: 1.1063 - output1_loss: 1.2072 - output2_loss: 2.1315 - output3_loss: 2.4953 - output4_loss: 2.0833 - output5_loss: 1.2065 - output6_loss: 1.1762   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 10\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 794s - loss: 11.0956 - output0_loss: 1.0920 - output1_loss: 1.1780 - output2_loss: 2.0893 - output3_loss: 2.3553 - output4_loss: 2.0378 - output5_loss: 1.1860 - output6_loss: 1.1572   \n",
      "Validation Acc: 0.0000\n",
      "Epoch: 11\n",
      "Epoch 1/1\n",
      "2672/7190 [==========>...................] - ETA: 555s - loss: 10.8470 - output0_loss: 1.0819 - output1_loss: 1.1461 - output2_loss: 2.0530 - output3_loss: 2.2661 - output4_loss: 1.9965 - output5_loss: 1.1578 - output6_loss: 1.1455"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8b6d265e8f72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     model.fit_generator(train_gen,\n\u001b[1;32m     30\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     epochs=1)    \n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m#                     validation_data=createGenerator(val_X, val_Y, val_datagen, batch_size=batch_size),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#                    validation_steps=len(val_X)//batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n",
    "#               patience=3, min_lr=0.00001)\n",
    "# model_chkpt = ModelCheckpoint(filepath=MODEL_NAME, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# hist = model.fit_generator(createGenerator(train_X, train_Y, train_datagen, batch_size=32),\n",
    "#                     steps_per_epoch=len(train_X)//batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=createGenerator(val_X, val_Y, val_datagen, batch_size=32),\n",
    "#                    validation_steps=len(val_X)//batch_size,\n",
    "#                     callbacks=[reduce_lr, model_chkpt]) # , model_chkpt Weird serialization error\n",
    "\n",
    "# hist = model.fit(train_X, {name:train_Y[:,idx] for idx, name in enumerate(output_names)}, batch_size=batch_size,\n",
    "#                 shuffle=True,\n",
    "#                 epochs=epochs,\n",
    "#                 validation_data=(val_X, {name:val_Y[:,idx] for idx, name in enumerate(output_names)}),\n",
    "#                 callbacks=[reduce_lr, model_chkpt])\n",
    "train_gen = createGenerator(train_X, train_Y, train_datagen, batch_size=batch_size)\n",
    "val_gen = createGenerator(val_X, val_Y, val_datagen, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 835s - loss: 9.9589 - output0_loss: 1.0297 - output1_loss: 1.0763 - output2_loss: 1.8591 - output3_loss: 1.9947 - output4_loss: 1.8333 - output5_loss: 1.0759 - output6_loss: 1.0899   \n",
      "Validation Acc: 0.2914\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 837s - loss: 9.7410 - output0_loss: 1.0127 - output1_loss: 1.0510 - output2_loss: 1.8113 - output3_loss: 1.9239 - output4_loss: 1.8140 - output5_loss: 1.0568 - output6_loss: 1.0712   \n",
      "Validation Acc: 0.2670\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 843s - loss: 9.5715 - output0_loss: 1.0010 - output1_loss: 1.0341 - output2_loss: 1.7643 - output3_loss: 1.8706 - output4_loss: 1.7992 - output5_loss: 1.0446 - output6_loss: 1.0576   \n",
      "Validation Acc: 0.3051\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 3\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 843s - loss: 9.4047 - output0_loss: 0.9883 - output1_loss: 1.0196 - output2_loss: 1.7160 - output3_loss: 1.8201 - output4_loss: 1.7847 - output5_loss: 1.0310 - output6_loss: 1.0450   \n",
      "Validation Acc: 0.3967\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 4\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 9.2719 - output0_loss: 0.9863 - output1_loss: 1.0132 - output2_loss: 1.6749 - output3_loss: 1.7717 - output4_loss: 1.7750 - output5_loss: 1.0163 - output6_loss: 1.0346   \n",
      "Validation Acc: 0.3509\n",
      "Epoch: 5\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 9.1259 - output0_loss: 0.9775 - output1_loss: 0.9994 - output2_loss: 1.6282 - output3_loss: 1.7351 - output4_loss: 1.7564 - output5_loss: 1.0078 - output6_loss: 1.0216   \n",
      "Validation Acc: 0.4242\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 6\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 9.0277 - output0_loss: 0.9787 - output1_loss: 0.9944 - output2_loss: 1.5928 - output3_loss: 1.6995 - output4_loss: 1.7355 - output5_loss: 1.0101 - output6_loss: 1.0166   \n",
      "Validation Acc: 0.4305\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 7\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 8.9052 - output0_loss: 0.9777 - output1_loss: 0.9871 - output2_loss: 1.5580 - output3_loss: 1.6636 - output4_loss: 1.7132 - output5_loss: 1.0013 - output6_loss: 1.0044   \n",
      "Validation Acc: 0.4550\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 8\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 8.8173 - output0_loss: 0.9752 - output1_loss: 0.9845 - output2_loss: 1.5233 - output3_loss: 1.6362 - output4_loss: 1.7003 - output5_loss: 0.9990 - output6_loss: 0.9988   \n",
      "Validation Acc: 0.4417\n",
      "Epoch: 9\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 850s - loss: 8.7345 - output0_loss: 0.9874 - output1_loss: 0.9762 - output2_loss: 1.4881 - output3_loss: 1.6084 - output4_loss: 1.6783 - output5_loss: 0.9993 - output6_loss: 0.9967   \n",
      "Validation Acc: 0.4519\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 10\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.6366 - output0_loss: 0.9849 - output1_loss: 0.9718 - output2_loss: 1.4626 - output3_loss: 1.5875 - output4_loss: 1.6514 - output5_loss: 0.9937 - output6_loss: 0.9848   \n",
      "Validation Acc: 0.4783\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 11\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.5529 - output0_loss: 0.9788 - output1_loss: 0.9708 - output2_loss: 1.4469 - output3_loss: 1.5595 - output4_loss: 1.6226 - output5_loss: 0.9910 - output6_loss: 0.9833   \n",
      "Validation Acc: 0.4869\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 12\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.4731 - output0_loss: 0.9739 - output1_loss: 0.9611 - output2_loss: 1.4287 - output3_loss: 1.5477 - output4_loss: 1.5977 - output5_loss: 0.9865 - output6_loss: 0.9775   \n",
      "Validation Acc: 0.4890\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 13\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.3978 - output0_loss: 0.9686 - output1_loss: 0.9568 - output2_loss: 1.4279 - output3_loss: 1.5317 - output4_loss: 1.5695 - output5_loss: 0.9765 - output6_loss: 0.9667   \n",
      "Validation Acc: 0.4704\n",
      "Epoch: 14\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.3360 - output0_loss: 0.9682 - output1_loss: 0.9495 - output2_loss: 1.4211 - output3_loss: 1.5161 - output4_loss: 1.5408 - output5_loss: 0.9725 - output6_loss: 0.9679   \n",
      "Validation Acc: 0.4931\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 15\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.2797 - output0_loss: 0.9651 - output1_loss: 0.9530 - output2_loss: 1.4138 - output3_loss: 1.5015 - output4_loss: 1.5170 - output5_loss: 0.9648 - output6_loss: 0.9645   \n",
      "Validation Acc: 0.4917\n",
      "Epoch: 16\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.2181 - output0_loss: 0.9595 - output1_loss: 0.9439 - output2_loss: 1.4160 - output3_loss: 1.4846 - output4_loss: 1.4868 - output5_loss: 0.9686 - output6_loss: 0.9587   \n",
      "Validation Acc: 0.5110\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 17\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.1588 - output0_loss: 0.9573 - output1_loss: 0.9419 - output2_loss: 1.4043 - output3_loss: 1.4718 - output4_loss: 1.4669 - output5_loss: 0.9598 - output6_loss: 0.9569   \n",
      "Validation Acc: 0.5128\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 18\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.0986 - output0_loss: 0.9518 - output1_loss: 0.9369 - output2_loss: 1.4037 - output3_loss: 1.4561 - output4_loss: 1.4422 - output5_loss: 0.9562 - output6_loss: 0.9516   \n",
      "Validation Acc: 0.4560\n",
      "Epoch: 19\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 8.0488 - output0_loss: 0.9479 - output1_loss: 0.9347 - output2_loss: 1.4017 - output3_loss: 1.4419 - output4_loss: 1.4239 - output5_loss: 0.9523 - output6_loss: 0.9463   \n",
      "Validation Acc: 0.4957\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 20\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 7.9973 - output0_loss: 0.9454 - output1_loss: 0.9322 - output2_loss: 1.3944 - output3_loss: 1.4230 - output4_loss: 1.4047 - output5_loss: 0.9506 - output6_loss: 0.9471   \n",
      "Validation Acc: 0.5295\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 21\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 7.9440 - output0_loss: 0.9430 - output1_loss: 0.9283 - output2_loss: 1.3832 - output3_loss: 1.4125 - output4_loss: 1.3930 - output5_loss: 0.9459 - output6_loss: 0.9383   \n",
      "Validation Acc: 0.5284\n",
      "Epoch: 22\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 7.8973 - output0_loss: 0.9364 - output1_loss: 0.9255 - output2_loss: 1.3771 - output3_loss: 1.3962 - output4_loss: 1.3807 - output5_loss: 0.9439 - output6_loss: 0.9376   \n",
      "Validation Acc: 0.5105\n",
      "Epoch: 23\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 7.8604 - output0_loss: 0.9372 - output1_loss: 0.9283 - output2_loss: 1.3708 - output3_loss: 1.3773 - output4_loss: 1.3701 - output5_loss: 0.9431 - output6_loss: 0.9336   \n",
      "Validation Acc: 0.4744\n",
      "Epoch: 24\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 7.8161 - output0_loss: 0.9329 - output1_loss: 0.9257 - output2_loss: 1.3593 - output3_loss: 1.3624 - output4_loss: 1.3606 - output5_loss: 0.9442 - output6_loss: 0.9310   \n",
      "Validation Acc: 0.5429\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 25\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 7.7843 - output0_loss: 0.9301 - output1_loss: 0.9223 - output2_loss: 1.3520 - output3_loss: 1.3530 - output4_loss: 1.3519 - output5_loss: 0.9450 - output6_loss: 0.9301   \n",
      "Validation Acc: 0.5444\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 26\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 7.7439 - output0_loss: 0.9334 - output1_loss: 0.9239 - output2_loss: 1.3381 - output3_loss: 1.3405 - output4_loss: 1.3353 - output5_loss: 0.9397 - output6_loss: 0.9330   \n",
      "Validation Acc: 0.5502\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 27\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 7.7043 - output0_loss: 0.9238 - output1_loss: 0.9172 - output2_loss: 1.3332 - output3_loss: 1.3331 - output4_loss: 1.3308 - output5_loss: 0.9385 - output6_loss: 0.9275   \n",
      "Validation Acc: 0.5324\n",
      "Epoch: 28\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 7.6452 - output0_loss: 0.9265 - output1_loss: 0.9071 - output2_loss: 1.3178 - output3_loss: 1.3170 - output4_loss: 1.3239 - output5_loss: 0.9305 - output6_loss: 0.9224   \n",
      "Validation Acc: 0.5448\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 29\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.6047 - output0_loss: 0.9137 - output1_loss: 0.9129 - output2_loss: 1.2997 - output3_loss: 1.3090 - output4_loss: 1.3151 - output5_loss: 0.9352 - output6_loss: 0.9192   \n",
      "Validation Acc: 0.5215\n",
      "Epoch: 30\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 7.5820 - output0_loss: 0.9156 - output1_loss: 0.9143 - output2_loss: 1.2875 - output3_loss: 1.3038 - output4_loss: 1.3079 - output5_loss: 0.9348 - output6_loss: 0.9181   \n",
      "Validation Acc: 0.5480\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 31\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.5377 - output0_loss: 0.9162 - output1_loss: 0.9107 - output2_loss: 1.2789 - output3_loss: 1.2858 - output4_loss: 1.3013 - output5_loss: 0.9268 - output6_loss: 0.9179   \n",
      "Validation Acc: 0.5362\n",
      "Epoch: 32\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 7.5027 - output0_loss: 0.9141 - output1_loss: 0.9096 - output2_loss: 1.2653 - output3_loss: 1.2724 - output4_loss: 1.3014 - output5_loss: 0.9241 - output6_loss: 0.9158   \n",
      "Validation Acc: 0.5437\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 33\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 7.4666 - output0_loss: 0.9086 - output1_loss: 0.9019 - output2_loss: 1.2660 - output3_loss: 1.2576 - output4_loss: 1.2913 - output5_loss: 0.9294 - output6_loss: 0.9118   \n",
      "Validation Acc: 0.5457\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 34\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 7.4302 - output0_loss: 0.9099 - output1_loss: 0.9021 - output2_loss: 1.2491 - output3_loss: 1.2442 - output4_loss: 1.2869 - output5_loss: 0.9250 - output6_loss: 0.9130   \n",
      "Validation Acc: 0.5539\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 35\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.3931 - output0_loss: 0.9060 - output1_loss: 0.8993 - output2_loss: 1.2473 - output3_loss: 1.2332 - output4_loss: 1.2764 - output5_loss: 0.9235 - output6_loss: 0.9074   \n",
      "Validation Acc: 0.5600\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 36\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.3606 - output0_loss: 0.8993 - output1_loss: 0.8990 - output2_loss: 1.2422 - output3_loss: 1.2181 - output4_loss: 1.2746 - output5_loss: 0.9183 - output6_loss: 0.9092   \n",
      "Validation Acc: 0.5600\n",
      "Epoch: 37\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 7.3295 - output0_loss: 0.9007 - output1_loss: 0.8976 - output2_loss: 1.2371 - output3_loss: 1.2086 - output4_loss: 1.2633 - output5_loss: 0.9217 - output6_loss: 0.9005   \n",
      "Validation Acc: 0.5486\n",
      "Epoch: 38\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.3110 - output0_loss: 0.9026 - output1_loss: 0.8980 - output2_loss: 1.2327 - output3_loss: 1.2011 - output4_loss: 1.2508 - output5_loss: 0.9194 - output6_loss: 0.9064   \n",
      "Validation Acc: 0.5653\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 39\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.2577 - output0_loss: 0.8995 - output1_loss: 0.8916 - output2_loss: 1.2276 - output3_loss: 1.1917 - output4_loss: 1.2409 - output5_loss: 0.9107 - output6_loss: 0.8956   \n",
      "Validation Acc: 0.5630\n",
      "Epoch: 40\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.2358 - output0_loss: 0.8971 - output1_loss: 0.8915 - output2_loss: 1.2238 - output3_loss: 1.1869 - output4_loss: 1.2246 - output5_loss: 0.9136 - output6_loss: 0.8983   \n",
      "Validation Acc: 0.5667\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 41\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.2008 - output0_loss: 0.8912 - output1_loss: 0.8893 - output2_loss: 1.2187 - output3_loss: 1.1820 - output4_loss: 1.2129 - output5_loss: 0.9082 - output6_loss: 0.8986   \n",
      "Validation Acc: 0.5531\n",
      "Epoch: 42\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.1706 - output0_loss: 0.8934 - output1_loss: 0.8863 - output2_loss: 1.2193 - output3_loss: 1.1819 - output4_loss: 1.1943 - output5_loss: 0.9081 - output6_loss: 0.8873   \n",
      "Validation Acc: 0.5625\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 43\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.1565 - output0_loss: 0.8890 - output1_loss: 0.8876 - output2_loss: 1.2133 - output3_loss: 1.1769 - output4_loss: 1.1877 - output5_loss: 0.9077 - output6_loss: 0.8944   \n",
      "Validation Acc: 0.5697\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 44\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.1182 - output0_loss: 0.8872 - output1_loss: 0.8822 - output2_loss: 1.2124 - output3_loss: 1.1764 - output4_loss: 1.1697 - output5_loss: 0.9047 - output6_loss: 0.8857   \n",
      "Validation Acc: 0.5552\n",
      "Epoch: 45\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.1096 - output0_loss: 0.8828 - output1_loss: 0.8840 - output2_loss: 1.2141 - output3_loss: 1.1717 - output4_loss: 1.1630 - output5_loss: 0.9065 - output6_loss: 0.8874   \n",
      "Validation Acc: 0.5646\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 46\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.0741 - output0_loss: 0.8865 - output1_loss: 0.8823 - output2_loss: 1.2133 - output3_loss: 1.1672 - output4_loss: 1.1369 - output5_loss: 0.9050 - output6_loss: 0.8829   \n",
      "Validation Acc: 0.5684\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 47\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 7.0532 - output0_loss: 0.8809 - output1_loss: 0.8824 - output2_loss: 1.2004 - output3_loss: 1.1653 - output4_loss: 1.1280 - output5_loss: 0.9051 - output6_loss: 0.8911   \n",
      "Validation Acc: 0.5641\n",
      "Epoch: 48\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 7.0362 - output0_loss: 0.8802 - output1_loss: 0.8810 - output2_loss: 1.2083 - output3_loss: 1.1616 - output4_loss: 1.1178 - output5_loss: 0.9024 - output6_loss: 0.8849   \n",
      "Validation Acc: 0.5668\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 49\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.9863 - output0_loss: 0.8705 - output1_loss: 0.8779 - output2_loss: 1.2001 - output3_loss: 1.1582 - output4_loss: 1.1029 - output5_loss: 0.8932 - output6_loss: 0.8834   \n",
      "Validation Acc: 0.5678\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 50\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.9790 - output0_loss: 0.8791 - output1_loss: 0.8763 - output2_loss: 1.2000 - output3_loss: 1.1518 - output4_loss: 1.0996 - output5_loss: 0.8951 - output6_loss: 0.8771   \n",
      "Validation Acc: 0.5566\n",
      "Epoch: 51\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.9566 - output0_loss: 0.8753 - output1_loss: 0.8736 - output2_loss: 1.1942 - output3_loss: 1.1477 - output4_loss: 1.0890 - output5_loss: 0.8941 - output6_loss: 0.8826   \n",
      "Validation Acc: 0.5626\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 52\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.9550 - output0_loss: 0.8781 - output1_loss: 0.8716 - output2_loss: 1.1926 - output3_loss: 1.1502 - output4_loss: 1.0867 - output5_loss: 0.8968 - output6_loss: 0.8791   \n",
      "Validation Acc: 0.5584\n",
      "Epoch: 53\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.9192 - output0_loss: 0.8682 - output1_loss: 0.8722 - output2_loss: 1.1876 - output3_loss: 1.1438 - output4_loss: 1.0753 - output5_loss: 0.8933 - output6_loss: 0.8787   \n",
      "Validation Acc: 0.5001\n",
      "Epoch: 54\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.9156 - output0_loss: 0.8671 - output1_loss: 0.8713 - output2_loss: 1.1834 - output3_loss: 1.1404 - output4_loss: 1.0770 - output5_loss: 0.8987 - output6_loss: 0.8777   \n",
      "Validation Acc: 0.5750\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 55\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.8803 - output0_loss: 0.8667 - output1_loss: 0.8688 - output2_loss: 1.1765 - output3_loss: 1.1374 - output4_loss: 1.0677 - output5_loss: 0.8899 - output6_loss: 0.8733   \n",
      "Validation Acc: 0.5714\n",
      "Epoch: 56\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.8603 - output0_loss: 0.8703 - output1_loss: 0.8678 - output2_loss: 1.1746 - output3_loss: 1.1274 - output4_loss: 1.0566 - output5_loss: 0.8866 - output6_loss: 0.8770   \n",
      "Validation Acc: 0.5708\n",
      "Epoch: 57\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.8536 - output0_loss: 0.8644 - output1_loss: 0.8733 - output2_loss: 1.1712 - output3_loss: 1.1288 - output4_loss: 1.0541 - output5_loss: 0.8909 - output6_loss: 0.8709   \n",
      "Validation Acc: 0.5752\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 58\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.8336 - output0_loss: 0.8645 - output1_loss: 0.8669 - output2_loss: 1.1707 - output3_loss: 1.1270 - output4_loss: 1.0489 - output5_loss: 0.8871 - output6_loss: 0.8686   \n",
      "Validation Acc: 0.5746\n",
      "Epoch: 59\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.8138 - output0_loss: 0.8588 - output1_loss: 0.8664 - output2_loss: 1.1687 - output3_loss: 1.1240 - output4_loss: 1.0429 - output5_loss: 0.8850 - output6_loss: 0.8681   \n",
      "Validation Acc: 0.5694\n",
      "Epoch: 60\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.7888 - output0_loss: 0.8636 - output1_loss: 0.8621 - output2_loss: 1.1628 - output3_loss: 1.1181 - output4_loss: 1.0318 - output5_loss: 0.8842 - output6_loss: 0.8661   \n",
      "Validation Acc: 0.5798\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 61\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.7818 - output0_loss: 0.8592 - output1_loss: 0.8617 - output2_loss: 1.1587 - output3_loss: 1.1181 - output4_loss: 1.0341 - output5_loss: 0.8801 - output6_loss: 0.8698   \n",
      "Validation Acc: 0.5790\n",
      "Epoch: 62\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.7668 - output0_loss: 0.8577 - output1_loss: 0.8613 - output2_loss: 1.1648 - output3_loss: 1.1133 - output4_loss: 1.0262 - output5_loss: 0.8786 - output6_loss: 0.8650   \n",
      "Validation Acc: 0.5841\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 63\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.7660 - output0_loss: 0.8577 - output1_loss: 0.8643 - output2_loss: 1.1611 - output3_loss: 1.1143 - output4_loss: 1.0245 - output5_loss: 0.8807 - output6_loss: 0.8634   \n",
      "Validation Acc: 0.5843\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 64\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 845s - loss: 6.7367 - output0_loss: 0.8568 - output1_loss: 0.8580 - output2_loss: 1.1545 - output3_loss: 1.1054 - output4_loss: 1.0188 - output5_loss: 0.8829 - output6_loss: 0.8603   \n",
      "Validation Acc: 0.5822\n",
      "Epoch: 65\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.7297 - output0_loss: 0.8550 - output1_loss: 0.8548 - output2_loss: 1.1561 - output3_loss: 1.1124 - output4_loss: 1.0101 - output5_loss: 0.8801 - output6_loss: 0.8612   \n",
      "Validation Acc: 0.5826\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 66\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.7097 - output0_loss: 0.8511 - output1_loss: 0.8590 - output2_loss: 1.1529 - output3_loss: 1.1038 - output4_loss: 1.0038 - output5_loss: 0.8796 - output6_loss: 0.8594   \n",
      "Validation Acc: 0.5823\n",
      "Epoch: 67\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.6922 - output0_loss: 0.8551 - output1_loss: 0.8497 - output2_loss: 1.1495 - output3_loss: 1.1030 - output4_loss: 1.0009 - output5_loss: 0.8765 - output6_loss: 0.8574   \n",
      "Validation Acc: 0.5842\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 68\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.6847 - output0_loss: 0.8510 - output1_loss: 0.8555 - output2_loss: 1.1500 - output3_loss: 1.1005 - output4_loss: 0.9986 - output5_loss: 0.8749 - output6_loss: 0.8543   \n",
      "Validation Acc: 0.5807\n",
      "Epoch: 69\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.6729 - output0_loss: 0.8470 - output1_loss: 0.8523 - output2_loss: 1.1463 - output3_loss: 1.0984 - output4_loss: 0.9972 - output5_loss: 0.8773 - output6_loss: 0.8543   \n",
      "Validation Acc: 0.5785\n",
      "Epoch: 70\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.6692 - output0_loss: 0.8530 - output1_loss: 0.8527 - output2_loss: 1.1406 - output3_loss: 1.0959 - output4_loss: 0.9974 - output5_loss: 0.8767 - output6_loss: 0.8529   \n",
      "Validation Acc: 0.5429\n",
      "Epoch: 71\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.6397 - output0_loss: 0.8429 - output1_loss: 0.8494 - output2_loss: 1.1449 - output3_loss: 1.0887 - output4_loss: 0.9910 - output5_loss: 0.8718 - output6_loss: 0.8510   \n",
      "Validation Acc: 0.5880\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 72\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.6452 - output0_loss: 0.8484 - output1_loss: 0.8537 - output2_loss: 1.1405 - output3_loss: 1.0915 - output4_loss: 0.9856 - output5_loss: 0.8749 - output6_loss: 0.8507   \n",
      "Validation Acc: 0.5818\n",
      "Epoch: 73\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.6304 - output0_loss: 0.8464 - output1_loss: 0.8507 - output2_loss: 1.1398 - output3_loss: 1.0853 - output4_loss: 0.9838 - output5_loss: 0.8721 - output6_loss: 0.8523   \n",
      "Validation Acc: 0.5347\n",
      "Epoch: 74\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.6137 - output0_loss: 0.8445 - output1_loss: 0.8460 - output2_loss: 1.1339 - output3_loss: 1.0826 - output4_loss: 0.9893 - output5_loss: 0.8680 - output6_loss: 0.8493   \n",
      "Validation Acc: 0.5831\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 75\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.5961 - output0_loss: 0.8403 - output1_loss: 0.8499 - output2_loss: 1.1393 - output3_loss: 1.0780 - output4_loss: 0.9749 - output5_loss: 0.8691 - output6_loss: 0.8446   \n",
      "Validation Acc: 0.5521\n",
      "Epoch: 76\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5967 - output0_loss: 0.8409 - output1_loss: 0.8476 - output2_loss: 1.1370 - output3_loss: 1.0782 - output4_loss: 0.9790 - output5_loss: 0.8661 - output6_loss: 0.8478   \n",
      "Validation Acc: 0.5869\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 77\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5793 - output0_loss: 0.8385 - output1_loss: 0.8486 - output2_loss: 1.1341 - output3_loss: 1.0714 - output4_loss: 0.9718 - output5_loss: 0.8657 - output6_loss: 0.8491   \n",
      "Validation Acc: 0.5844\n",
      "Epoch: 78\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.5767 - output0_loss: 0.8401 - output1_loss: 0.8455 - output2_loss: 1.1315 - output3_loss: 1.0737 - output4_loss: 0.9748 - output5_loss: 0.8673 - output6_loss: 0.8438   \n",
      "Validation Acc: 0.5858\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 79\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5641 - output0_loss: 0.8359 - output1_loss: 0.8402 - output2_loss: 1.1305 - output3_loss: 1.0708 - output4_loss: 0.9723 - output5_loss: 0.8694 - output6_loss: 0.8449   \n",
      "Validation Acc: 0.5855\n",
      "Epoch: 80\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5524 - output0_loss: 0.8409 - output1_loss: 0.8425 - output2_loss: 1.1291 - output3_loss: 1.0705 - output4_loss: 0.9636 - output5_loss: 0.8657 - output6_loss: 0.8400   \n",
      "Validation Acc: 0.5874\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 81\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5371 - output0_loss: 0.8406 - output1_loss: 0.8415 - output2_loss: 1.1247 - output3_loss: 1.0578 - output4_loss: 0.9679 - output5_loss: 0.8605 - output6_loss: 0.8440   \n",
      "Validation Acc: 0.5872\n",
      "Epoch: 82\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5368 - output0_loss: 0.8383 - output1_loss: 0.8409 - output2_loss: 1.1229 - output3_loss: 1.0665 - output4_loss: 0.9642 - output5_loss: 0.8602 - output6_loss: 0.8439   \n",
      "Validation Acc: 0.5863\n",
      "Epoch: 83\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5252 - output0_loss: 0.8376 - output1_loss: 0.8365 - output2_loss: 1.1221 - output3_loss: 1.0604 - output4_loss: 0.9606 - output5_loss: 0.8661 - output6_loss: 0.8419   \n",
      "Validation Acc: 0.5881\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 84\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5211 - output0_loss: 0.8321 - output1_loss: 0.8422 - output2_loss: 1.1239 - output3_loss: 1.0606 - output4_loss: 0.9660 - output5_loss: 0.8579 - output6_loss: 0.8383   \n",
      "Validation Acc: 0.5810\n",
      "Epoch: 85\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.5195 - output0_loss: 0.8347 - output1_loss: 0.8407 - output2_loss: 1.1255 - output3_loss: 1.0582 - output4_loss: 0.9636 - output5_loss: 0.8591 - output6_loss: 0.8378   \n",
      "Validation Acc: 0.5766\n",
      "Epoch: 86\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4911 - output0_loss: 0.8334 - output1_loss: 0.8326 - output2_loss: 1.1220 - output3_loss: 1.0533 - output4_loss: 0.9537 - output5_loss: 0.8577 - output6_loss: 0.8384   \n",
      "Validation Acc: 0.5883\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 87\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 6.4933 - output0_loss: 0.8295 - output1_loss: 0.8352 - output2_loss: 1.1231 - output3_loss: 1.0555 - output4_loss: 0.9537 - output5_loss: 0.8627 - output6_loss: 0.8337   \n",
      "Validation Acc: 0.5880\n",
      "Epoch: 88\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4792 - output0_loss: 0.8302 - output1_loss: 0.8351 - output2_loss: 1.1181 - output3_loss: 1.0480 - output4_loss: 0.9576 - output5_loss: 0.8587 - output6_loss: 0.8315   \n",
      "Validation Acc: 0.5859\n",
      "Epoch: 89\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4781 - output0_loss: 0.8262 - output1_loss: 0.8323 - output2_loss: 1.1195 - output3_loss: 1.0469 - output4_loss: 0.9562 - output5_loss: 0.8598 - output6_loss: 0.8372   \n",
      "Validation Acc: 0.5780\n",
      "Epoch: 90\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4670 - output0_loss: 0.8310 - output1_loss: 0.8321 - output2_loss: 1.1172 - output3_loss: 1.0462 - output4_loss: 0.9500 - output5_loss: 0.8572 - output6_loss: 0.8332   \n",
      "Validation Acc: 0.5843\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 91\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4418 - output0_loss: 0.8238 - output1_loss: 0.8302 - output2_loss: 1.1038 - output3_loss: 1.0413 - output4_loss: 0.9536 - output5_loss: 0.8555 - output6_loss: 0.8337   \n",
      "Validation Acc: 0.5728\n",
      "Epoch: 92\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4547 - output0_loss: 0.8302 - output1_loss: 0.8352 - output2_loss: 1.1143 - output3_loss: 1.0391 - output4_loss: 0.9541 - output5_loss: 0.8556 - output6_loss: 0.8262   \n",
      "Validation Acc: 0.5919\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 93\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4470 - output0_loss: 0.8227 - output1_loss: 0.8337 - output2_loss: 1.1089 - output3_loss: 1.0403 - output4_loss: 0.9514 - output5_loss: 0.8579 - output6_loss: 0.8321   \n",
      "Validation Acc: 0.5939\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 94\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4370 - output0_loss: 0.8231 - output1_loss: 0.8378 - output2_loss: 1.1120 - output3_loss: 1.0340 - output4_loss: 0.9476 - output5_loss: 0.8513 - output6_loss: 0.8313   \n",
      "Validation Acc: 0.5905\n",
      "Epoch: 95\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.4241 - output0_loss: 0.8179 - output1_loss: 0.8292 - output2_loss: 1.1105 - output3_loss: 1.0353 - output4_loss: 0.9496 - output5_loss: 0.8551 - output6_loss: 0.8265   \n",
      "Validation Acc: 0.5587\n",
      "Epoch: 96\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.4254 - output0_loss: 0.8241 - output1_loss: 0.8323 - output2_loss: 1.1081 - output3_loss: 1.0317 - output4_loss: 0.9483 - output5_loss: 0.8504 - output6_loss: 0.8305   \n",
      "Validation Acc: 0.5680\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 97\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.4217 - output0_loss: 0.8188 - output1_loss: 0.8357 - output2_loss: 1.1096 - output3_loss: 1.0298 - output4_loss: 0.9482 - output5_loss: 0.8497 - output6_loss: 0.8299   \n",
      "Validation Acc: 0.5878\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 98\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.4178 - output0_loss: 0.8194 - output1_loss: 0.8309 - output2_loss: 1.1116 - output3_loss: 1.0317 - output4_loss: 0.9447 - output5_loss: 0.8521 - output6_loss: 0.8274   \n",
      "Validation Acc: 0.5440\n",
      "Epoch: 99\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3949 - output0_loss: 0.8190 - output1_loss: 0.8298 - output2_loss: 1.1026 - output3_loss: 1.0287 - output4_loss: 0.9439 - output5_loss: 0.8486 - output6_loss: 0.8223   \n",
      "Validation Acc: 0.5837\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 100\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3964 - output0_loss: 0.8201 - output1_loss: 0.8331 - output2_loss: 1.1050 - output3_loss: 1.0246 - output4_loss: 0.9409 - output5_loss: 0.8498 - output6_loss: 0.8229   \n",
      "Validation Acc: 0.5895\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 101\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3800 - output0_loss: 0.8217 - output1_loss: 0.8287 - output2_loss: 1.1024 - output3_loss: 1.0185 - output4_loss: 0.9435 - output5_loss: 0.8427 - output6_loss: 0.8226   \n",
      "Validation Acc: 0.5821\n",
      "Epoch: 102\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3879 - output0_loss: 0.8169 - output1_loss: 0.8313 - output2_loss: 1.1016 - output3_loss: 1.0227 - output4_loss: 0.9418 - output5_loss: 0.8481 - output6_loss: 0.8256   \n",
      "Validation Acc: 0.5949\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 103\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.3725 - output0_loss: 0.8204 - output1_loss: 0.8230 - output2_loss: 1.1000 - output3_loss: 1.0173 - output4_loss: 0.9396 - output5_loss: 0.8498 - output6_loss: 0.8224   \n",
      "Validation Acc: 0.5720\n",
      "Epoch: 104\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3753 - output0_loss: 0.8213 - output1_loss: 0.8286 - output2_loss: 1.1055 - output3_loss: 1.0166 - output4_loss: 0.9343 - output5_loss: 0.8464 - output6_loss: 0.8226   \n",
      "Validation Acc: 0.5917\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 105\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3613 - output0_loss: 0.8161 - output1_loss: 0.8253 - output2_loss: 1.0996 - output3_loss: 1.0154 - output4_loss: 0.9396 - output5_loss: 0.8416 - output6_loss: 0.8237   \n",
      "Validation Acc: 0.5911\n",
      "Epoch: 106\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3588 - output0_loss: 0.8127 - output1_loss: 0.8288 - output2_loss: 1.1001 - output3_loss: 1.0144 - output4_loss: 0.9380 - output5_loss: 0.8445 - output6_loss: 0.8202   \n",
      "Validation Acc: 0.5940\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 107\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 846s - loss: 6.3513 - output0_loss: 0.8180 - output1_loss: 0.8267 - output2_loss: 1.0968 - output3_loss: 1.0137 - output4_loss: 0.9343 - output5_loss: 0.8474 - output6_loss: 0.8145   \n",
      "Validation Acc: 0.5803\n",
      "Epoch: 108\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3234 - output0_loss: 0.8098 - output1_loss: 0.8224 - output2_loss: 1.0945 - output3_loss: 1.0092 - output4_loss: 0.9323 - output5_loss: 0.8375 - output6_loss: 0.8178   \n",
      "Validation Acc: 0.5945\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 109\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3316 - output0_loss: 0.8149 - output1_loss: 0.8220 - output2_loss: 1.0955 - output3_loss: 1.0079 - output4_loss: 0.9293 - output5_loss: 0.8419 - output6_loss: 0.8201   \n",
      "Validation Acc: 0.5943\n",
      "Epoch: 110\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3366 - output0_loss: 0.8126 - output1_loss: 0.8227 - output2_loss: 1.1014 - output3_loss: 1.0049 - output4_loss: 0.9323 - output5_loss: 0.8437 - output6_loss: 0.8190   \n",
      "Validation Acc: 0.5928\n",
      "Epoch: 111\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3095 - output0_loss: 0.8031 - output1_loss: 0.8254 - output2_loss: 1.0930 - output3_loss: 1.0010 - output4_loss: 0.9311 - output5_loss: 0.8396 - output6_loss: 0.8163   \n",
      "Validation Acc: 0.5919\n",
      "Epoch: 112\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3296 - output0_loss: 0.8126 - output1_loss: 0.8195 - output2_loss: 1.0966 - output3_loss: 0.9989 - output4_loss: 0.9329 - output5_loss: 0.8470 - output6_loss: 0.8221   \n",
      "Validation Acc: 0.5883\n",
      "Epoch: 113\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 847s - loss: 6.3055 - output0_loss: 0.8099 - output1_loss: 0.8192 - output2_loss: 1.0929 - output3_loss: 0.9971 - output4_loss: 0.9247 - output5_loss: 0.8456 - output6_loss: 0.8161   \n",
      "Validation Acc: 0.5903\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 114\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.3092 - output0_loss: 0.8126 - output1_loss: 0.8254 - output2_loss: 1.0992 - output3_loss: 0.9926 - output4_loss: 0.9260 - output5_loss: 0.8375 - output6_loss: 0.8158   \n",
      "Validation Acc: 0.5894\n",
      "Epoch: 115\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.3090 - output0_loss: 0.8083 - output1_loss: 0.8210 - output2_loss: 1.0971 - output3_loss: 0.9937 - output4_loss: 0.9291 - output5_loss: 0.8418 - output6_loss: 0.8181   \n",
      "Validation Acc: 0.5941\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 116\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.2961 - output0_loss: 0.8063 - output1_loss: 0.8216 - output2_loss: 1.0932 - output3_loss: 0.9912 - output4_loss: 0.9244 - output5_loss: 0.8459 - output6_loss: 0.8135   \n",
      "Validation Acc: 0.5995\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 117\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.2908 - output0_loss: 0.8135 - output1_loss: 0.8206 - output2_loss: 1.0911 - output3_loss: 0.9870 - output4_loss: 0.9244 - output5_loss: 0.8389 - output6_loss: 0.8154   \n",
      "Validation Acc: 0.5868\n",
      "Epoch: 118\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.2798 - output0_loss: 0.8023 - output1_loss: 0.8201 - output2_loss: 1.0906 - output3_loss: 0.9894 - output4_loss: 0.9246 - output5_loss: 0.8384 - output6_loss: 0.8145   \n",
      "Validation Acc: 0.5938\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 119\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 848s - loss: 6.2740 - output0_loss: 0.8074 - output1_loss: 0.8144 - output2_loss: 1.0895 - output3_loss: 0.9841 - output4_loss: 0.9260 - output5_loss: 0.8373 - output6_loss: 0.8152   \n",
      "Validation Acc: 0.5957\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 120\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 6.2689 - output0_loss: 0.8081 - output1_loss: 0.8203 - output2_loss: 1.0889 - output3_loss: 0.9796 - output4_loss: 0.9270 - output5_loss: 0.8366 - output6_loss: 0.8084   \n",
      "Validation Acc: 0.5932\n",
      "Epoch: 121\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 6.2767 - output0_loss: 0.8041 - output1_loss: 0.8184 - output2_loss: 1.0913 - output3_loss: 0.9817 - output4_loss: 0.9261 - output5_loss: 0.8429 - output6_loss: 0.8121   \n",
      "Validation Acc: 0.5972\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 122\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 6.2694 - output0_loss: 0.8060 - output1_loss: 0.8163 - output2_loss: 1.0893 - output3_loss: 0.9810 - output4_loss: 0.9267 - output5_loss: 0.8408 - output6_loss: 0.8094   \n",
      "Validation Acc: 0.5880\n",
      "Epoch: 123\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 849s - loss: 6.2590 - output0_loss: 0.8080 - output1_loss: 0.8188 - output2_loss: 1.0925 - output3_loss: 0.9785 - output4_loss: 0.9173 - output5_loss: 0.8390 - output6_loss: 0.8048   \n",
      "Validation Acc: 0.5942\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 124\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 851s - loss: 6.2463 - output0_loss: 0.8035 - output1_loss: 0.8147 - output2_loss: 1.0847 - output3_loss: 0.9759 - output4_loss: 0.9224 - output5_loss: 0.8350 - output6_loss: 0.8101   \n",
      "Validation Acc: 0.5336\n",
      "Epoch: 125\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 851s - loss: 6.2508 - output0_loss: 0.8037 - output1_loss: 0.8171 - output2_loss: 1.0859 - output3_loss: 0.9738 - output4_loss: 0.9236 - output5_loss: 0.8379 - output6_loss: 0.8087   \n",
      "Validation Acc: 0.5975\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 126\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 851s - loss: 6.2479 - output0_loss: 0.8018 - output1_loss: 0.8151 - output2_loss: 1.0860 - output3_loss: 0.9732 - output4_loss: 0.9228 - output5_loss: 0.8435 - output6_loss: 0.8055   \n",
      "Validation Acc: 0.5965\n",
      "Epoch: 127\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 851s - loss: 6.2335 - output0_loss: 0.8039 - output1_loss: 0.8155 - output2_loss: 1.0879 - output3_loss: 0.9726 - output4_loss: 0.9162 - output5_loss: 0.8340 - output6_loss: 0.8035   \n",
      "Validation Acc: 0.5910\n",
      "Epoch: 128\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 851s - loss: 6.2173 - output0_loss: 0.7999 - output1_loss: 0.8126 - output2_loss: 1.0819 - output3_loss: 0.9671 - output4_loss: 0.9184 - output5_loss: 0.8336 - output6_loss: 0.8038   \n",
      "Validation Acc: 0.5964\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 129\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 852s - loss: 6.2197 - output0_loss: 0.7982 - output1_loss: 0.8134 - output2_loss: 1.0899 - output3_loss: 0.9688 - output4_loss: 0.9106 - output5_loss: 0.8346 - output6_loss: 0.8041   \n",
      "Validation Acc: 0.5795\n",
      "Epoch: 130\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 852s - loss: 6.2089 - output0_loss: 0.7990 - output1_loss: 0.8199 - output2_loss: 1.0842 - output3_loss: 0.9653 - output4_loss: 0.9102 - output5_loss: 0.8275 - output6_loss: 0.8029   \n",
      "Validation Acc: 0.5997\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 131\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 853s - loss: 6.2053 - output0_loss: 0.7971 - output1_loss: 0.8144 - output2_loss: 1.0815 - output3_loss: 0.9555 - output4_loss: 0.9193 - output5_loss: 0.8333 - output6_loss: 0.8041   \n",
      "Validation Acc: 0.5922\n",
      "Epoch: 132\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 853s - loss: 6.2017 - output0_loss: 0.8014 - output1_loss: 0.8115 - output2_loss: 1.0825 - output3_loss: 0.9618 - output4_loss: 0.9120 - output5_loss: 0.8307 - output6_loss: 0.8017   \n",
      "Validation Acc: 0.5975\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 133\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 854s - loss: 6.1978 - output0_loss: 0.7984 - output1_loss: 0.8107 - output2_loss: 1.0790 - output3_loss: 0.9571 - output4_loss: 0.9187 - output5_loss: 0.8340 - output6_loss: 0.8000   \n",
      "Validation Acc: 0.5961\n",
      "Epoch: 134\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 854s - loss: 6.1904 - output0_loss: 0.7986 - output1_loss: 0.8108 - output2_loss: 1.0789 - output3_loss: 0.9565 - output4_loss: 0.9166 - output5_loss: 0.8312 - output6_loss: 0.7980   \n",
      "Validation Acc: 0.5816\n",
      "Epoch: 135\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 854s - loss: 6.1975 - output0_loss: 0.8008 - output1_loss: 0.8150 - output2_loss: 1.0774 - output3_loss: 0.9556 - output4_loss: 0.9153 - output5_loss: 0.8328 - output6_loss: 0.8006   \n",
      "Validation Acc: 0.5997\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 136\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 854s - loss: 6.1853 - output0_loss: 0.7954 - output1_loss: 0.8077 - output2_loss: 1.0817 - output3_loss: 0.9556 - output4_loss: 0.9162 - output5_loss: 0.8300 - output6_loss: 0.7986   \n",
      "Validation Acc: 0.5971\n",
      "Epoch: 137\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 855s - loss: 6.1827 - output0_loss: 0.7958 - output1_loss: 0.8088 - output2_loss: 1.0707 - output3_loss: 0.9533 - output4_loss: 0.9145 - output5_loss: 0.8369 - output6_loss: 0.8026   \n",
      "Validation Acc: 0.6000\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 138\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 855s - loss: 6.1832 - output0_loss: 0.7957 - output1_loss: 0.8116 - output2_loss: 1.0807 - output3_loss: 0.9486 - output4_loss: 0.9147 - output5_loss: 0.8287 - output6_loss: 0.8032   \n",
      "Validation Acc: 0.5964\n",
      "Epoch: 139\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 855s - loss: 6.1718 - output0_loss: 0.7949 - output1_loss: 0.8138 - output2_loss: 1.0758 - output3_loss: 0.9481 - output4_loss: 0.9083 - output5_loss: 0.8314 - output6_loss: 0.7995   \n",
      "Validation Acc: 0.5967\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 140\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1619 - output0_loss: 0.7920 - output1_loss: 0.8062 - output2_loss: 1.0751 - output3_loss: 0.9467 - output4_loss: 0.9117 - output5_loss: 0.8301 - output6_loss: 0.8000   \n",
      "Validation Acc: 0.5997\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 141\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1610 - output0_loss: 0.7925 - output1_loss: 0.8077 - output2_loss: 1.0810 - output3_loss: 0.9423 - output4_loss: 0.9113 - output5_loss: 0.8277 - output6_loss: 0.7985   \n",
      "Validation Acc: 0.5969\n",
      "Epoch: 142\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1553 - output0_loss: 0.7914 - output1_loss: 0.8065 - output2_loss: 1.0748 - output3_loss: 0.9443 - output4_loss: 0.9109 - output5_loss: 0.8342 - output6_loss: 0.7932   \n",
      "Validation Acc: 0.5993\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 143\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1624 - output0_loss: 0.7914 - output1_loss: 0.8080 - output2_loss: 1.0789 - output3_loss: 0.9439 - output4_loss: 0.9129 - output5_loss: 0.8303 - output6_loss: 0.7971   \n",
      "Validation Acc: 0.5964\n",
      "Epoch: 144\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 857s - loss: 6.1452 - output0_loss: 0.7913 - output1_loss: 0.8066 - output2_loss: 1.0707 - output3_loss: 0.9448 - output4_loss: 0.9106 - output5_loss: 0.8297 - output6_loss: 0.7915   \n",
      "Validation Acc: 0.6014\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 145\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1489 - output0_loss: 0.7919 - output1_loss: 0.8047 - output2_loss: 1.0754 - output3_loss: 0.9396 - output4_loss: 0.9080 - output5_loss: 0.8308 - output6_loss: 0.7985   \n",
      "Validation Acc: 0.5962\n",
      "Epoch: 146\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 857s - loss: 6.1499 - output0_loss: 0.7919 - output1_loss: 0.8095 - output2_loss: 1.0753 - output3_loss: 0.9387 - output4_loss: 0.9055 - output5_loss: 0.8329 - output6_loss: 0.7960   \n",
      "Validation Acc: 0.5990\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 147\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 857s - loss: 6.1299 - output0_loss: 0.7896 - output1_loss: 0.8057 - output2_loss: 1.0687 - output3_loss: 0.9396 - output4_loss: 0.9058 - output5_loss: 0.8307 - output6_loss: 0.7899   \n",
      "Validation Acc: 0.5879\n",
      "Epoch: 148\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 857s - loss: 6.1294 - output0_loss: 0.7860 - output1_loss: 0.8055 - output2_loss: 1.0739 - output3_loss: 0.9397 - output4_loss: 0.9022 - output5_loss: 0.8251 - output6_loss: 0.7970   \n",
      "Validation Acc: 0.5916\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 149\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 857s - loss: 6.1251 - output0_loss: 0.7845 - output1_loss: 0.8085 - output2_loss: 1.0700 - output3_loss: 0.9346 - output4_loss: 0.9090 - output5_loss: 0.8277 - output6_loss: 0.7909   \n",
      "Validation Acc: 0.6015\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 150\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 857s - loss: 6.1180 - output0_loss: 0.7857 - output1_loss: 0.8059 - output2_loss: 1.0670 - output3_loss: 0.9348 - output4_loss: 0.9051 - output5_loss: 0.8309 - output6_loss: 0.7885   \n",
      "Validation Acc: 0.5998\n",
      "Epoch: 151\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1132 - output0_loss: 0.7832 - output1_loss: 0.8069 - output2_loss: 1.0691 - output3_loss: 0.9357 - output4_loss: 0.8992 - output5_loss: 0.8304 - output6_loss: 0.7887   \n",
      "Validation Acc: 0.6014\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 152\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1120 - output0_loss: 0.7885 - output1_loss: 0.8061 - output2_loss: 1.0666 - output3_loss: 0.9298 - output4_loss: 0.9068 - output5_loss: 0.8267 - output6_loss: 0.7874   \n",
      "Validation Acc: 0.5984\n",
      "Epoch: 153\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 857s - loss: 6.1073 - output0_loss: 0.7813 - output1_loss: 0.8041 - output2_loss: 1.0681 - output3_loss: 0.9304 - output4_loss: 0.9043 - output5_loss: 0.8273 - output6_loss: 0.7919   \n",
      "Validation Acc: 0.6005\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 154\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1064 - output0_loss: 0.7895 - output1_loss: 0.8036 - output2_loss: 1.0639 - output3_loss: 0.9289 - output4_loss: 0.9042 - output5_loss: 0.8272 - output6_loss: 0.7891   \n",
      "Validation Acc: 0.5999\n",
      "Epoch: 155\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1110 - output0_loss: 0.7901 - output1_loss: 0.8009 - output2_loss: 1.0668 - output3_loss: 0.9296 - output4_loss: 0.9048 - output5_loss: 0.8311 - output6_loss: 0.7878   \n",
      "Validation Acc: 0.5955\n",
      "Epoch: 156\n",
      "Epoch 1/1\n",
      "7191/7190 [==============================] - 856s - loss: 6.1086 - output0_loss: 0.7872 - output1_loss: 0.8043 - output2_loss: 1.0704 - output3_loss: 0.9329 - output4_loss: 0.9024 - output5_loss: 0.8229 - output6_loss: 0.7884   \n",
      "Validation Acc: 0.5961\n",
      "Saving improved model 7char_stage2_exp01.h5\n",
      "Epoch: 157\n",
      "Epoch 1/1\n",
      "1334/7190 [====>.........................] - ETA: 699s - loss: 6.1099 - output0_loss: 0.7906 - output1_loss: 0.8100 - output2_loss: 1.0599 - output3_loss: 0.9256 - output4_loss: 0.9097 - output5_loss: 0.8288 - output6_loss: 0.7852"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2633efb055c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     model.fit_generator(train_gen,\n\u001b[1;32m      8\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     epochs=1)    \n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#                     validation_data=createGenerator(val_X, val_Y, val_datagen, batch_size=batch_size),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#                    validation_steps=len(val_X)//batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Perform manual iteration\n",
    "hist_acc = []\n",
    "best_acc = 0.0\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: %d\"%epoch)\n",
    "    model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=len(train_X)/batch_size,\n",
    "                    epochs=1)    \n",
    "#                     validation_data=createGenerator(val_X, val_Y, val_datagen, batch_size=batch_size),\n",
    "#                    validation_steps=len(val_X)//batch_size\n",
    "    \n",
    "#     model.fit(train_X, {name:train_Y[:,idx] for idx, name in enumerate(output_names)}, batch_size=batch_size,\n",
    "#                     shuffle=True,\n",
    "#                     epochs=1)\n",
    "    #Evaluate validation here\n",
    "    preds = model.predict(val_X/255.0)\n",
    "#     preds = model.predict_generator(val_gen, steps=len(val_X)/batch_size)\n",
    "    preds = np.concatenate([np.argmax(preds[idx], axis=1).reshape(-1, 1) for idx in range(len(preds))], axis=1)\n",
    "    epoch_val_acc = custom_accuracy(val_Y, preds)\n",
    "    print(\"Validation Acc: %.4f\"%epoch_val_acc)\n",
    "    hist_acc.append(epoch_val_acc)\n",
    "    #Check for improvement\n",
    "    if len(hist_acc) == 1 or hist_acc[-1] > best_acc[-2]:\n",
    "        # Save model\n",
    "        print(\"Saving improved model %s\"%MODEL_NAME)\n",
    "        model.save(MODEL_NAME)\n",
    "        best_acc = epoch_val_acc"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
